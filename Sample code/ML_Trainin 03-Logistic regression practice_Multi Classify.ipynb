{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression practice \n",
    "- Multi Classify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset from sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orginal data shape：(150, 4), Label data shape：(150,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "\n",
    "x_org, y_org = iris.data, iris.target\n",
    "print('Orginal data shape：{}, Label data shape：{}'.format(x_org.shape, y_org.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of orginal data：(150,)\n",
      "shape after One Hot-encoding：(150, 3)\n"
     ]
    }
   ],
   "source": [
    "# do ONE-HOT ENCODING \n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "ohe = OneHotEncoder(sparse=False, categories='auto')\n",
    "y_all_one = ohe.fit_transform(np.c_[y_org])\n",
    "print('Shape of orginal data：{}'.format(y_org.shape))\n",
    "print('shape after One Hot-encoding：{}'.format(y_all_one.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "insert dummy variable (150, 5)\n"
     ]
    }
   ],
   "source": [
    "x_data_insert = np.insert(x_org, 0, 1.0, axis=1)\n",
    "print('insert dummy variable', x_data_insert.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split dataset\n",
    "- Split data into 50% training data and 50% testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of ...：\n",
      " x_train：(75, 5), x_test：(75, 5), y_train：(75,), y_test：(75,), y_train_one：(75, 3), y_test_one：(75, 3)\n",
      "label y = [1 1 0 2 2]\n",
      "label y after one ot encoding = [[0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test, y_train_one, y_test_one = train_test_split(\n",
    "    x_data_insert, y_org, y_all_one, train_size=75, test_size=75, random_state=123)\n",
    "\n",
    "print(\"shape of ...：\"+\"\\n\"+ \" x_train：{}, x_test：{}, y_train：{}, y_test：{}, y_train_one：{}, y_test_one：{}\"\n",
    "     .format(x_train.shape, x_test.shape, y_train.shape, y_test.shape, \n",
    "    y_train_one.shape, y_test_one.shape))\n",
    "\n",
    "print(\"label y =\", (y_train[:5]) )\n",
    "print(\"label y after one ot encoding =\", (y_train_one[:5,:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function define"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Softmax function \n",
    "- softmax 函式將陣列中的所有元素在區間 (0,1) 內進行歸一化處理，使其可以作為概率處理。\n",
    "- 應用softmax時，常見的問題是數值穩定性問題，也就是說，由於可能出現的指數和溢位誤差，∑j e^(z_j)可能會變得非常大。這個溢位誤差可以通過用陣列的每個值減去其最大值來解決。\n",
    "![Softmax](https://www.delftstack.com/img/Numpy/softmax%20formula.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):   \n",
    "    max_row = np.max(x, axis=1, keepdims=True) # returns max of each row and keeps same dims\n",
    "    e_x = np.exp(x - max_row)                  # subtracts each row with its max value\n",
    "    sum_e = np.sum(e_x, axis=1, keepdims=True) # returns sum of each row and keeps same dims\n",
    "    f_x = e_x / sum_e \n",
    "    return f_x\n",
    "\n",
    "def predict_(x, w):\n",
    "    return softmax(np.dot(x, w))\n",
    "\n",
    "def cross_entropy(yt, yp):\n",
    "    return -np.mean(np.sum(yt * np.log(yp), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):   \n",
    "    ### Code here ### \n",
    "    return f_x\n",
    "\n",
    "def predict_(x, w):\n",
    "    return ### ?????? ###\n",
    "\n",
    "def cross_entropy(yt, yp):\n",
    "    return ### ?????? ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def evaluate(x_test, y_test, y_test_one, weight):\n",
    "    pred_y_test_one = predict_(x_test, weight)\n",
    "    pred_y_test = np.argmax(pred_y_test_one, axis=1)\n",
    "\n",
    "    loss = cross_entropy(y_test_one, pred_y_test_one)\n",
    "    score = accuracy_score(y_test, pred_y_test)\n",
    "    return loss, score\n",
    "\n",
    "def train(x_train, y_train_one, x_test, y_test, lr, iteration):\n",
    "    num_data = x_train.shape[0] # 樣本數\n",
    "    dim_data = x_train.shape[1] # 輸入資料的 shape\n",
    "    num_class = y_train_one.shape[1]    # 有幾個分類\n",
    "    \n",
    "    # intizlize weight and loss repository\n",
    "    weight = np.ones((dim_data, num_class)) \n",
    "    loss_repos = np.zeros((0, num_class))\n",
    "\n",
    "    for k in range(iteration):\n",
    "        pred_y = predict_(x_train, weight)\n",
    "        err = pred_y - y_train_one\n",
    "        weight = weight - lr * np.dot(x_train.T, err) / num_data\n",
    "        if (k % 10 == 0):\n",
    "            loss, score = evaluate(x_test, y_test, y_test_one, weight)\n",
    "            loss_repos = np.vstack((loss_repos, np.array([k, loss, score])))\n",
    "            print(\"epoch = %d loss = %f score = %f\" % (k, loss, score))\n",
    "    return loss_repos, weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set epoch and iteration\n",
    "iteration = 10000\n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 0 loss = 1.091583 score = 0.266667\n",
      "epoch = 10 loss = 1.041711 score = 0.266667\n",
      "epoch = 20 loss = 0.988501 score = 0.266667\n",
      "epoch = 30 loss = 0.939962 score = 0.573333\n",
      "epoch = 40 loss = 0.897037 score = 0.626667\n",
      "epoch = 50 loss = 0.859177 score = 0.626667\n",
      "epoch = 60 loss = 0.825724 score = 0.626667\n",
      "epoch = 70 loss = 0.796070 score = 0.626667\n",
      "epoch = 80 loss = 0.769683 score = 0.653333\n",
      "epoch = 90 loss = 0.746103 score = 0.653333\n",
      "epoch = 100 loss = 0.724936 score = 0.693333\n",
      "epoch = 110 loss = 0.705850 score = 0.746667\n",
      "epoch = 120 loss = 0.688561 score = 0.760000\n",
      "epoch = 130 loss = 0.672832 score = 0.760000\n",
      "epoch = 140 loss = 0.658461 score = 0.786667\n",
      "epoch = 150 loss = 0.645275 score = 0.786667\n",
      "epoch = 160 loss = 0.633131 score = 0.786667\n",
      "epoch = 170 loss = 0.621903 score = 0.813333\n",
      "epoch = 180 loss = 0.611485 score = 0.813333\n",
      "epoch = 190 loss = 0.601788 score = 0.840000\n",
      "epoch = 200 loss = 0.592731 score = 0.840000\n",
      "epoch = 210 loss = 0.584248 score = 0.880000\n",
      "epoch = 220 loss = 0.576280 score = 0.880000\n",
      "epoch = 230 loss = 0.568774 score = 0.893333\n",
      "epoch = 240 loss = 0.561688 score = 0.906667\n",
      "epoch = 250 loss = 0.554980 score = 0.906667\n",
      "epoch = 260 loss = 0.548618 score = 0.906667\n",
      "epoch = 270 loss = 0.542569 score = 0.906667\n",
      "epoch = 280 loss = 0.536808 score = 0.906667\n",
      "epoch = 290 loss = 0.531310 score = 0.906667\n",
      "epoch = 300 loss = 0.526054 score = 0.906667\n",
      "epoch = 310 loss = 0.521020 score = 0.906667\n",
      "epoch = 320 loss = 0.516192 score = 0.906667\n",
      "epoch = 330 loss = 0.511554 score = 0.906667\n",
      "epoch = 340 loss = 0.507093 score = 0.906667\n",
      "epoch = 350 loss = 0.502795 score = 0.906667\n",
      "epoch = 360 loss = 0.498650 score = 0.906667\n",
      "epoch = 370 loss = 0.494647 score = 0.906667\n",
      "epoch = 380 loss = 0.490777 score = 0.906667\n",
      "epoch = 390 loss = 0.487031 score = 0.906667\n",
      "epoch = 400 loss = 0.483402 score = 0.906667\n",
      "epoch = 410 loss = 0.479882 score = 0.906667\n",
      "epoch = 420 loss = 0.476466 score = 0.906667\n",
      "epoch = 430 loss = 0.473146 score = 0.906667\n",
      "epoch = 440 loss = 0.469918 score = 0.906667\n",
      "epoch = 450 loss = 0.466777 score = 0.906667\n",
      "epoch = 460 loss = 0.463717 score = 0.906667\n",
      "epoch = 470 loss = 0.460735 score = 0.906667\n",
      "epoch = 480 loss = 0.457826 score = 0.906667\n",
      "epoch = 490 loss = 0.454987 score = 0.906667\n",
      "epoch = 500 loss = 0.452214 score = 0.906667\n",
      "epoch = 510 loss = 0.449505 score = 0.906667\n",
      "epoch = 520 loss = 0.446856 score = 0.906667\n",
      "epoch = 530 loss = 0.444264 score = 0.906667\n",
      "epoch = 540 loss = 0.441727 score = 0.906667\n",
      "epoch = 550 loss = 0.439242 score = 0.906667\n",
      "epoch = 560 loss = 0.436808 score = 0.906667\n",
      "epoch = 570 loss = 0.434422 score = 0.906667\n",
      "epoch = 580 loss = 0.432081 score = 0.906667\n",
      "epoch = 590 loss = 0.429785 score = 0.920000\n",
      "epoch = 600 loss = 0.427532 score = 0.920000\n",
      "epoch = 610 loss = 0.425319 score = 0.920000\n",
      "epoch = 620 loss = 0.423146 score = 0.920000\n",
      "epoch = 630 loss = 0.421010 score = 0.920000\n",
      "epoch = 640 loss = 0.418911 score = 0.920000\n",
      "epoch = 650 loss = 0.416846 score = 0.920000\n",
      "epoch = 660 loss = 0.414816 score = 0.920000\n",
      "epoch = 670 loss = 0.412819 score = 0.920000\n",
      "epoch = 680 loss = 0.410853 score = 0.920000\n",
      "epoch = 690 loss = 0.408917 score = 0.920000\n",
      "epoch = 700 loss = 0.407011 score = 0.920000\n",
      "epoch = 710 loss = 0.405134 score = 0.920000\n",
      "epoch = 720 loss = 0.403285 score = 0.920000\n",
      "epoch = 730 loss = 0.401462 score = 0.920000\n",
      "epoch = 740 loss = 0.399666 score = 0.920000\n",
      "epoch = 750 loss = 0.397895 score = 0.920000\n",
      "epoch = 760 loss = 0.396148 score = 0.920000\n",
      "epoch = 770 loss = 0.394426 score = 0.933333\n",
      "epoch = 780 loss = 0.392726 score = 0.933333\n",
      "epoch = 790 loss = 0.391049 score = 0.933333\n",
      "epoch = 800 loss = 0.389395 score = 0.933333\n",
      "epoch = 810 loss = 0.387761 score = 0.933333\n",
      "epoch = 820 loss = 0.386148 score = 0.933333\n",
      "epoch = 830 loss = 0.384556 score = 0.933333\n",
      "epoch = 840 loss = 0.382984 score = 0.933333\n",
      "epoch = 850 loss = 0.381430 score = 0.946667\n",
      "epoch = 860 loss = 0.379896 score = 0.946667\n",
      "epoch = 870 loss = 0.378380 score = 0.946667\n",
      "epoch = 880 loss = 0.376882 score = 0.946667\n",
      "epoch = 890 loss = 0.375401 score = 0.946667\n",
      "epoch = 900 loss = 0.373938 score = 0.946667\n",
      "epoch = 910 loss = 0.372491 score = 0.946667\n",
      "epoch = 920 loss = 0.371061 score = 0.946667\n",
      "epoch = 930 loss = 0.369646 score = 0.946667\n",
      "epoch = 940 loss = 0.368248 score = 0.946667\n",
      "epoch = 950 loss = 0.366864 score = 0.946667\n",
      "epoch = 960 loss = 0.365496 score = 0.960000\n",
      "epoch = 970 loss = 0.364142 score = 0.960000\n",
      "epoch = 980 loss = 0.362803 score = 0.960000\n",
      "epoch = 990 loss = 0.361478 score = 0.960000\n",
      "epoch = 1000 loss = 0.360167 score = 0.960000\n",
      "epoch = 1010 loss = 0.358869 score = 0.960000\n",
      "epoch = 1020 loss = 0.357585 score = 0.960000\n",
      "epoch = 1030 loss = 0.356313 score = 0.960000\n",
      "epoch = 1040 loss = 0.355055 score = 0.960000\n",
      "epoch = 1050 loss = 0.353809 score = 0.960000\n",
      "epoch = 1060 loss = 0.352575 score = 0.960000\n",
      "epoch = 1070 loss = 0.351354 score = 0.960000\n",
      "epoch = 1080 loss = 0.350144 score = 0.960000\n",
      "epoch = 1090 loss = 0.348946 score = 0.960000\n",
      "epoch = 1100 loss = 0.347760 score = 0.960000\n",
      "epoch = 1110 loss = 0.346585 score = 0.960000\n",
      "epoch = 1120 loss = 0.345421 score = 0.960000\n",
      "epoch = 1130 loss = 0.344268 score = 0.960000\n",
      "epoch = 1140 loss = 0.343126 score = 0.960000\n",
      "epoch = 1150 loss = 0.341994 score = 0.960000\n",
      "epoch = 1160 loss = 0.340873 score = 0.960000\n",
      "epoch = 1170 loss = 0.339761 score = 0.960000\n",
      "epoch = 1180 loss = 0.338660 score = 0.960000\n",
      "epoch = 1190 loss = 0.337569 score = 0.960000\n",
      "epoch = 1200 loss = 0.336488 score = 0.960000\n",
      "epoch = 1210 loss = 0.335416 score = 0.960000\n",
      "epoch = 1220 loss = 0.334354 score = 0.960000\n",
      "epoch = 1230 loss = 0.333300 score = 0.960000\n",
      "epoch = 1240 loss = 0.332257 score = 0.960000\n",
      "epoch = 1250 loss = 0.331222 score = 0.960000\n",
      "epoch = 1260 loss = 0.330196 score = 0.960000\n",
      "epoch = 1270 loss = 0.329179 score = 0.960000\n",
      "epoch = 1280 loss = 0.328170 score = 0.960000\n",
      "epoch = 1290 loss = 0.327170 score = 0.960000\n",
      "epoch = 1300 loss = 0.326179 score = 0.960000\n",
      "epoch = 1310 loss = 0.325195 score = 0.960000\n",
      "epoch = 1320 loss = 0.324220 score = 0.960000\n",
      "epoch = 1330 loss = 0.323253 score = 0.960000\n",
      "epoch = 1340 loss = 0.322294 score = 0.960000\n",
      "epoch = 1350 loss = 0.321343 score = 0.960000\n",
      "epoch = 1360 loss = 0.320399 score = 0.960000\n",
      "epoch = 1370 loss = 0.319463 score = 0.960000\n",
      "epoch = 1380 loss = 0.318535 score = 0.960000\n",
      "epoch = 1390 loss = 0.317614 score = 0.960000\n",
      "epoch = 1400 loss = 0.316700 score = 0.960000\n",
      "epoch = 1410 loss = 0.315794 score = 0.960000\n",
      "epoch = 1420 loss = 0.314895 score = 0.960000\n",
      "epoch = 1430 loss = 0.314003 score = 0.960000\n",
      "epoch = 1440 loss = 0.313117 score = 0.960000\n",
      "epoch = 1450 loss = 0.312239 score = 0.960000\n",
      "epoch = 1460 loss = 0.311367 score = 0.960000\n",
      "epoch = 1470 loss = 0.310503 score = 0.960000\n",
      "epoch = 1480 loss = 0.309645 score = 0.960000\n",
      "epoch = 1490 loss = 0.308793 score = 0.960000\n",
      "epoch = 1500 loss = 0.307948 score = 0.960000\n",
      "epoch = 1510 loss = 0.307109 score = 0.960000\n",
      "epoch = 1520 loss = 0.306276 score = 0.960000\n",
      "epoch = 1530 loss = 0.305450 score = 0.960000\n",
      "epoch = 1540 loss = 0.304630 score = 0.960000\n",
      "epoch = 1550 loss = 0.303816 score = 0.960000\n",
      "epoch = 1560 loss = 0.303008 score = 0.960000\n",
      "epoch = 1570 loss = 0.302206 score = 0.960000\n",
      "epoch = 1580 loss = 0.301410 score = 0.960000\n",
      "epoch = 1590 loss = 0.300620 score = 0.960000\n",
      "epoch = 1600 loss = 0.299835 score = 0.960000\n",
      "epoch = 1610 loss = 0.299056 score = 0.960000\n",
      "epoch = 1620 loss = 0.298283 score = 0.960000\n",
      "epoch = 1630 loss = 0.297516 score = 0.960000\n",
      "epoch = 1640 loss = 0.296753 score = 0.960000\n",
      "epoch = 1650 loss = 0.295997 score = 0.960000\n",
      "epoch = 1660 loss = 0.295245 score = 0.960000\n",
      "epoch = 1670 loss = 0.294499 score = 0.960000\n",
      "epoch = 1680 loss = 0.293758 score = 0.960000\n",
      "epoch = 1690 loss = 0.293023 score = 0.960000\n",
      "epoch = 1700 loss = 0.292292 score = 0.960000\n",
      "epoch = 1710 loss = 0.291567 score = 0.960000\n",
      "epoch = 1720 loss = 0.290846 score = 0.960000\n",
      "epoch = 1730 loss = 0.290131 score = 0.960000\n",
      "epoch = 1740 loss = 0.289421 score = 0.960000\n",
      "epoch = 1750 loss = 0.288715 score = 0.960000\n",
      "epoch = 1760 loss = 0.288014 score = 0.960000\n",
      "epoch = 1770 loss = 0.287318 score = 0.960000\n",
      "epoch = 1780 loss = 0.286627 score = 0.960000\n",
      "epoch = 1790 loss = 0.285940 score = 0.960000\n",
      "epoch = 1800 loss = 0.285258 score = 0.960000\n",
      "epoch = 1810 loss = 0.284581 score = 0.960000\n",
      "epoch = 1820 loss = 0.283908 score = 0.960000\n",
      "epoch = 1830 loss = 0.283240 score = 0.960000\n",
      "epoch = 1840 loss = 0.282576 score = 0.960000\n",
      "epoch = 1850 loss = 0.281916 score = 0.960000\n",
      "epoch = 1860 loss = 0.281261 score = 0.960000\n",
      "epoch = 1870 loss = 0.280610 score = 0.960000\n",
      "epoch = 1880 loss = 0.279963 score = 0.960000\n",
      "epoch = 1890 loss = 0.279321 score = 0.960000\n",
      "epoch = 1900 loss = 0.278683 score = 0.960000\n",
      "epoch = 1910 loss = 0.278049 score = 0.960000\n",
      "epoch = 1920 loss = 0.277419 score = 0.960000\n",
      "epoch = 1930 loss = 0.276793 score = 0.960000\n",
      "epoch = 1940 loss = 0.276171 score = 0.960000\n",
      "epoch = 1950 loss = 0.275553 score = 0.960000\n",
      "epoch = 1960 loss = 0.274939 score = 0.960000\n",
      "epoch = 1970 loss = 0.274329 score = 0.960000\n",
      "epoch = 1980 loss = 0.273722 score = 0.960000\n",
      "epoch = 1990 loss = 0.273120 score = 0.960000\n",
      "epoch = 2000 loss = 0.272521 score = 0.960000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 2010 loss = 0.271927 score = 0.960000\n",
      "epoch = 2020 loss = 0.271335 score = 0.960000\n",
      "epoch = 2030 loss = 0.270748 score = 0.960000\n",
      "epoch = 2040 loss = 0.270164 score = 0.960000\n",
      "epoch = 2050 loss = 0.269584 score = 0.960000\n",
      "epoch = 2060 loss = 0.269007 score = 0.960000\n",
      "epoch = 2070 loss = 0.268434 score = 0.960000\n",
      "epoch = 2080 loss = 0.267865 score = 0.960000\n",
      "epoch = 2090 loss = 0.267299 score = 0.960000\n",
      "epoch = 2100 loss = 0.266736 score = 0.960000\n",
      "epoch = 2110 loss = 0.266177 score = 0.960000\n",
      "epoch = 2120 loss = 0.265621 score = 0.960000\n",
      "epoch = 2130 loss = 0.265069 score = 0.960000\n",
      "epoch = 2140 loss = 0.264520 score = 0.960000\n",
      "epoch = 2150 loss = 0.263974 score = 0.960000\n",
      "epoch = 2160 loss = 0.263431 score = 0.960000\n",
      "epoch = 2170 loss = 0.262892 score = 0.960000\n",
      "epoch = 2180 loss = 0.262356 score = 0.960000\n",
      "epoch = 2190 loss = 0.261823 score = 0.960000\n",
      "epoch = 2200 loss = 0.261293 score = 0.960000\n",
      "epoch = 2210 loss = 0.260767 score = 0.960000\n",
      "epoch = 2220 loss = 0.260243 score = 0.960000\n",
      "epoch = 2230 loss = 0.259723 score = 0.960000\n",
      "epoch = 2240 loss = 0.259205 score = 0.960000\n",
      "epoch = 2250 loss = 0.258691 score = 0.960000\n",
      "epoch = 2260 loss = 0.258179 score = 0.960000\n",
      "epoch = 2270 loss = 0.257671 score = 0.960000\n",
      "epoch = 2280 loss = 0.257165 score = 0.960000\n",
      "epoch = 2290 loss = 0.256663 score = 0.960000\n",
      "epoch = 2300 loss = 0.256163 score = 0.960000\n",
      "epoch = 2310 loss = 0.255666 score = 0.960000\n",
      "epoch = 2320 loss = 0.255172 score = 0.960000\n",
      "epoch = 2330 loss = 0.254681 score = 0.960000\n",
      "epoch = 2340 loss = 0.254193 score = 0.960000\n",
      "epoch = 2350 loss = 0.253707 score = 0.960000\n",
      "epoch = 2360 loss = 0.253224 score = 0.960000\n",
      "epoch = 2370 loss = 0.252744 score = 0.960000\n",
      "epoch = 2380 loss = 0.252267 score = 0.960000\n",
      "epoch = 2390 loss = 0.251792 score = 0.960000\n",
      "epoch = 2400 loss = 0.251320 score = 0.960000\n",
      "epoch = 2410 loss = 0.250850 score = 0.960000\n",
      "epoch = 2420 loss = 0.250383 score = 0.960000\n",
      "epoch = 2430 loss = 0.249919 score = 0.960000\n",
      "epoch = 2440 loss = 0.249457 score = 0.960000\n",
      "epoch = 2450 loss = 0.248998 score = 0.960000\n",
      "epoch = 2460 loss = 0.248542 score = 0.960000\n",
      "epoch = 2470 loss = 0.248087 score = 0.960000\n",
      "epoch = 2480 loss = 0.247636 score = 0.960000\n",
      "epoch = 2490 loss = 0.247187 score = 0.960000\n",
      "epoch = 2500 loss = 0.246740 score = 0.960000\n",
      "epoch = 2510 loss = 0.246296 score = 0.960000\n",
      "epoch = 2520 loss = 0.245854 score = 0.960000\n",
      "epoch = 2530 loss = 0.245414 score = 0.960000\n",
      "epoch = 2540 loss = 0.244977 score = 0.960000\n",
      "epoch = 2550 loss = 0.244542 score = 0.960000\n",
      "epoch = 2560 loss = 0.244110 score = 0.960000\n",
      "epoch = 2570 loss = 0.243679 score = 0.960000\n",
      "epoch = 2580 loss = 0.243252 score = 0.960000\n",
      "epoch = 2590 loss = 0.242826 score = 0.960000\n",
      "epoch = 2600 loss = 0.242403 score = 0.960000\n",
      "epoch = 2610 loss = 0.241981 score = 0.960000\n",
      "epoch = 2620 loss = 0.241562 score = 0.960000\n",
      "epoch = 2630 loss = 0.241146 score = 0.960000\n",
      "epoch = 2640 loss = 0.240731 score = 0.960000\n",
      "epoch = 2650 loss = 0.240319 score = 0.960000\n",
      "epoch = 2660 loss = 0.239909 score = 0.960000\n",
      "epoch = 2670 loss = 0.239501 score = 0.960000\n",
      "epoch = 2680 loss = 0.239095 score = 0.960000\n",
      "epoch = 2690 loss = 0.238691 score = 0.960000\n",
      "epoch = 2700 loss = 0.238289 score = 0.960000\n",
      "epoch = 2710 loss = 0.237889 score = 0.960000\n",
      "epoch = 2720 loss = 0.237492 score = 0.960000\n",
      "epoch = 2730 loss = 0.237096 score = 0.960000\n",
      "epoch = 2740 loss = 0.236703 score = 0.960000\n",
      "epoch = 2750 loss = 0.236311 score = 0.960000\n",
      "epoch = 2760 loss = 0.235921 score = 0.960000\n",
      "epoch = 2770 loss = 0.235534 score = 0.960000\n",
      "epoch = 2780 loss = 0.235148 score = 0.960000\n",
      "epoch = 2790 loss = 0.234765 score = 0.960000\n",
      "epoch = 2800 loss = 0.234383 score = 0.960000\n",
      "epoch = 2810 loss = 0.234003 score = 0.960000\n",
      "epoch = 2820 loss = 0.233625 score = 0.960000\n",
      "epoch = 2830 loss = 0.233249 score = 0.960000\n",
      "epoch = 2840 loss = 0.232875 score = 0.960000\n",
      "epoch = 2850 loss = 0.232502 score = 0.960000\n",
      "epoch = 2860 loss = 0.232132 score = 0.960000\n",
      "epoch = 2870 loss = 0.231763 score = 0.960000\n",
      "epoch = 2880 loss = 0.231397 score = 0.960000\n",
      "epoch = 2890 loss = 0.231032 score = 0.960000\n",
      "epoch = 2900 loss = 0.230668 score = 0.960000\n",
      "epoch = 2910 loss = 0.230307 score = 0.960000\n",
      "epoch = 2920 loss = 0.229947 score = 0.960000\n",
      "epoch = 2930 loss = 0.229589 score = 0.960000\n",
      "epoch = 2940 loss = 0.229233 score = 0.960000\n",
      "epoch = 2950 loss = 0.228879 score = 0.960000\n",
      "epoch = 2960 loss = 0.228526 score = 0.960000\n",
      "epoch = 2970 loss = 0.228175 score = 0.960000\n",
      "epoch = 2980 loss = 0.227826 score = 0.960000\n",
      "epoch = 2990 loss = 0.227478 score = 0.960000\n",
      "epoch = 3000 loss = 0.227132 score = 0.960000\n",
      "epoch = 3010 loss = 0.226788 score = 0.960000\n",
      "epoch = 3020 loss = 0.226445 score = 0.960000\n",
      "epoch = 3030 loss = 0.226104 score = 0.960000\n",
      "epoch = 3040 loss = 0.225765 score = 0.960000\n",
      "epoch = 3050 loss = 0.225427 score = 0.960000\n",
      "epoch = 3060 loss = 0.225091 score = 0.960000\n",
      "epoch = 3070 loss = 0.224756 score = 0.960000\n",
      "epoch = 3080 loss = 0.224423 score = 0.960000\n",
      "epoch = 3090 loss = 0.224092 score = 0.960000\n",
      "epoch = 3100 loss = 0.223762 score = 0.960000\n",
      "epoch = 3110 loss = 0.223433 score = 0.960000\n",
      "epoch = 3120 loss = 0.223107 score = 0.960000\n",
      "epoch = 3130 loss = 0.222781 score = 0.960000\n",
      "epoch = 3140 loss = 0.222457 score = 0.960000\n",
      "epoch = 3150 loss = 0.222135 score = 0.960000\n",
      "epoch = 3160 loss = 0.221814 score = 0.960000\n",
      "epoch = 3170 loss = 0.221495 score = 0.960000\n",
      "epoch = 3180 loss = 0.221177 score = 0.960000\n",
      "epoch = 3190 loss = 0.220861 score = 0.960000\n",
      "epoch = 3200 loss = 0.220546 score = 0.960000\n",
      "epoch = 3210 loss = 0.220232 score = 0.960000\n",
      "epoch = 3220 loss = 0.219920 score = 0.960000\n",
      "epoch = 3230 loss = 0.219610 score = 0.960000\n",
      "epoch = 3240 loss = 0.219300 score = 0.960000\n",
      "epoch = 3250 loss = 0.218993 score = 0.960000\n",
      "epoch = 3260 loss = 0.218686 score = 0.960000\n",
      "epoch = 3270 loss = 0.218381 score = 0.960000\n",
      "epoch = 3280 loss = 0.218077 score = 0.960000\n",
      "epoch = 3290 loss = 0.217775 score = 0.960000\n",
      "epoch = 3300 loss = 0.217474 score = 0.960000\n",
      "epoch = 3310 loss = 0.217174 score = 0.960000\n",
      "epoch = 3320 loss = 0.216876 score = 0.960000\n",
      "epoch = 3330 loss = 0.216579 score = 0.960000\n",
      "epoch = 3340 loss = 0.216284 score = 0.960000\n",
      "epoch = 3350 loss = 0.215989 score = 0.960000\n",
      "epoch = 3360 loss = 0.215696 score = 0.960000\n",
      "epoch = 3370 loss = 0.215404 score = 0.960000\n",
      "epoch = 3380 loss = 0.215114 score = 0.960000\n",
      "epoch = 3390 loss = 0.214825 score = 0.960000\n",
      "epoch = 3400 loss = 0.214537 score = 0.960000\n",
      "epoch = 3410 loss = 0.214250 score = 0.960000\n",
      "epoch = 3420 loss = 0.213965 score = 0.960000\n",
      "epoch = 3430 loss = 0.213681 score = 0.960000\n",
      "epoch = 3440 loss = 0.213398 score = 0.960000\n",
      "epoch = 3450 loss = 0.213116 score = 0.960000\n",
      "epoch = 3460 loss = 0.212836 score = 0.960000\n",
      "epoch = 3470 loss = 0.212556 score = 0.960000\n",
      "epoch = 3480 loss = 0.212278 score = 0.960000\n",
      "epoch = 3490 loss = 0.212002 score = 0.960000\n",
      "epoch = 3500 loss = 0.211726 score = 0.960000\n",
      "epoch = 3510 loss = 0.211451 score = 0.960000\n",
      "epoch = 3520 loss = 0.211178 score = 0.960000\n",
      "epoch = 3530 loss = 0.210906 score = 0.960000\n",
      "epoch = 3540 loss = 0.210635 score = 0.960000\n",
      "epoch = 3550 loss = 0.210365 score = 0.960000\n",
      "epoch = 3560 loss = 0.210096 score = 0.960000\n",
      "epoch = 3570 loss = 0.209829 score = 0.960000\n",
      "epoch = 3580 loss = 0.209563 score = 0.960000\n",
      "epoch = 3590 loss = 0.209297 score = 0.960000\n",
      "epoch = 3600 loss = 0.209033 score = 0.960000\n",
      "epoch = 3610 loss = 0.208770 score = 0.960000\n",
      "epoch = 3620 loss = 0.208508 score = 0.960000\n",
      "epoch = 3630 loss = 0.208247 score = 0.960000\n",
      "epoch = 3640 loss = 0.207987 score = 0.960000\n",
      "epoch = 3650 loss = 0.207729 score = 0.960000\n",
      "epoch = 3660 loss = 0.207471 score = 0.960000\n",
      "epoch = 3670 loss = 0.207214 score = 0.960000\n",
      "epoch = 3680 loss = 0.206959 score = 0.960000\n",
      "epoch = 3690 loss = 0.206705 score = 0.960000\n",
      "epoch = 3700 loss = 0.206451 score = 0.960000\n",
      "epoch = 3710 loss = 0.206199 score = 0.960000\n",
      "epoch = 3720 loss = 0.205947 score = 0.960000\n",
      "epoch = 3730 loss = 0.205697 score = 0.960000\n",
      "epoch = 3740 loss = 0.205448 score = 0.960000\n",
      "epoch = 3750 loss = 0.205200 score = 0.960000\n",
      "epoch = 3760 loss = 0.204952 score = 0.960000\n",
      "epoch = 3770 loss = 0.204706 score = 0.960000\n",
      "epoch = 3780 loss = 0.204461 score = 0.960000\n",
      "epoch = 3790 loss = 0.204217 score = 0.960000\n",
      "epoch = 3800 loss = 0.203973 score = 0.960000\n",
      "epoch = 3810 loss = 0.203731 score = 0.960000\n",
      "epoch = 3820 loss = 0.203490 score = 0.960000\n",
      "epoch = 3830 loss = 0.203249 score = 0.960000\n",
      "epoch = 3840 loss = 0.203010 score = 0.960000\n",
      "epoch = 3850 loss = 0.202772 score = 0.960000\n",
      "epoch = 3860 loss = 0.202534 score = 0.960000\n",
      "epoch = 3870 loss = 0.202298 score = 0.960000\n",
      "epoch = 3880 loss = 0.202062 score = 0.960000\n",
      "epoch = 3890 loss = 0.201827 score = 0.960000\n",
      "epoch = 3900 loss = 0.201594 score = 0.960000\n",
      "epoch = 3910 loss = 0.201361 score = 0.960000\n",
      "epoch = 3920 loss = 0.201129 score = 0.960000\n",
      "epoch = 3930 loss = 0.200898 score = 0.960000\n",
      "epoch = 3940 loss = 0.200668 score = 0.960000\n",
      "epoch = 3950 loss = 0.200439 score = 0.960000\n",
      "epoch = 3960 loss = 0.200211 score = 0.960000\n",
      "epoch = 3970 loss = 0.199983 score = 0.960000\n",
      "epoch = 3980 loss = 0.199757 score = 0.960000\n",
      "epoch = 3990 loss = 0.199531 score = 0.960000\n",
      "epoch = 4000 loss = 0.199306 score = 0.960000\n",
      "epoch = 4010 loss = 0.199083 score = 0.960000\n",
      "epoch = 4020 loss = 0.198860 score = 0.960000\n",
      "epoch = 4030 loss = 0.198638 score = 0.960000\n",
      "epoch = 4040 loss = 0.198416 score = 0.960000\n",
      "epoch = 4050 loss = 0.198196 score = 0.960000\n",
      "epoch = 4060 loss = 0.197976 score = 0.960000\n",
      "epoch = 4070 loss = 0.197758 score = 0.960000\n",
      "epoch = 4080 loss = 0.197540 score = 0.960000\n",
      "epoch = 4090 loss = 0.197323 score = 0.960000\n",
      "epoch = 4100 loss = 0.197106 score = 0.960000\n",
      "epoch = 4110 loss = 0.196891 score = 0.960000\n",
      "epoch = 4120 loss = 0.196676 score = 0.960000\n",
      "epoch = 4130 loss = 0.196463 score = 0.960000\n",
      "epoch = 4140 loss = 0.196250 score = 0.960000\n",
      "epoch = 4150 loss = 0.196037 score = 0.960000\n",
      "epoch = 4160 loss = 0.195826 score = 0.960000\n",
      "epoch = 4170 loss = 0.195615 score = 0.960000\n",
      "epoch = 4180 loss = 0.195406 score = 0.960000\n",
      "epoch = 4190 loss = 0.195197 score = 0.960000\n",
      "epoch = 4200 loss = 0.194988 score = 0.960000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 4210 loss = 0.194781 score = 0.960000\n",
      "epoch = 4220 loss = 0.194574 score = 0.960000\n",
      "epoch = 4230 loss = 0.194368 score = 0.960000\n",
      "epoch = 4240 loss = 0.194163 score = 0.960000\n",
      "epoch = 4250 loss = 0.193959 score = 0.960000\n",
      "epoch = 4260 loss = 0.193755 score = 0.960000\n",
      "epoch = 4270 loss = 0.193552 score = 0.960000\n",
      "epoch = 4280 loss = 0.193350 score = 0.960000\n",
      "epoch = 4290 loss = 0.193149 score = 0.960000\n",
      "epoch = 4300 loss = 0.192948 score = 0.960000\n",
      "epoch = 4310 loss = 0.192748 score = 0.960000\n",
      "epoch = 4320 loss = 0.192549 score = 0.960000\n",
      "epoch = 4330 loss = 0.192351 score = 0.960000\n",
      "epoch = 4340 loss = 0.192153 score = 0.960000\n",
      "epoch = 4350 loss = 0.191956 score = 0.960000\n",
      "epoch = 4360 loss = 0.191760 score = 0.960000\n",
      "epoch = 4370 loss = 0.191564 score = 0.960000\n",
      "epoch = 4380 loss = 0.191369 score = 0.960000\n",
      "epoch = 4390 loss = 0.191175 score = 0.960000\n",
      "epoch = 4400 loss = 0.190982 score = 0.960000\n",
      "epoch = 4410 loss = 0.190789 score = 0.960000\n",
      "epoch = 4420 loss = 0.190597 score = 0.960000\n",
      "epoch = 4430 loss = 0.190405 score = 0.960000\n",
      "epoch = 4440 loss = 0.190215 score = 0.960000\n",
      "epoch = 4450 loss = 0.190025 score = 0.960000\n",
      "epoch = 4460 loss = 0.189835 score = 0.960000\n",
      "epoch = 4470 loss = 0.189647 score = 0.960000\n",
      "epoch = 4480 loss = 0.189459 score = 0.960000\n",
      "epoch = 4490 loss = 0.189271 score = 0.960000\n",
      "epoch = 4500 loss = 0.189085 score = 0.960000\n",
      "epoch = 4510 loss = 0.188899 score = 0.960000\n",
      "epoch = 4520 loss = 0.188713 score = 0.960000\n",
      "epoch = 4530 loss = 0.188529 score = 0.960000\n",
      "epoch = 4540 loss = 0.188345 score = 0.960000\n",
      "epoch = 4550 loss = 0.188161 score = 0.960000\n",
      "epoch = 4560 loss = 0.187978 score = 0.960000\n",
      "epoch = 4570 loss = 0.187796 score = 0.960000\n",
      "epoch = 4580 loss = 0.187615 score = 0.960000\n",
      "epoch = 4590 loss = 0.187434 score = 0.960000\n",
      "epoch = 4600 loss = 0.187254 score = 0.960000\n",
      "epoch = 4610 loss = 0.187074 score = 0.960000\n",
      "epoch = 4620 loss = 0.186895 score = 0.960000\n",
      "epoch = 4630 loss = 0.186717 score = 0.960000\n",
      "epoch = 4640 loss = 0.186539 score = 0.960000\n",
      "epoch = 4650 loss = 0.186362 score = 0.960000\n",
      "epoch = 4660 loss = 0.186185 score = 0.960000\n",
      "epoch = 4670 loss = 0.186009 score = 0.960000\n",
      "epoch = 4680 loss = 0.185834 score = 0.960000\n",
      "epoch = 4690 loss = 0.185659 score = 0.960000\n",
      "epoch = 4700 loss = 0.185485 score = 0.960000\n",
      "epoch = 4710 loss = 0.185312 score = 0.960000\n",
      "epoch = 4720 loss = 0.185139 score = 0.960000\n",
      "epoch = 4730 loss = 0.184967 score = 0.960000\n",
      "epoch = 4740 loss = 0.184795 score = 0.960000\n",
      "epoch = 4750 loss = 0.184624 score = 0.960000\n",
      "epoch = 4760 loss = 0.184453 score = 0.960000\n",
      "epoch = 4770 loss = 0.184283 score = 0.960000\n",
      "epoch = 4780 loss = 0.184114 score = 0.960000\n",
      "epoch = 4790 loss = 0.183945 score = 0.960000\n",
      "epoch = 4800 loss = 0.183776 score = 0.960000\n",
      "epoch = 4810 loss = 0.183609 score = 0.960000\n",
      "epoch = 4820 loss = 0.183442 score = 0.960000\n",
      "epoch = 4830 loss = 0.183275 score = 0.960000\n",
      "epoch = 4840 loss = 0.183109 score = 0.960000\n",
      "epoch = 4850 loss = 0.182943 score = 0.960000\n",
      "epoch = 4860 loss = 0.182779 score = 0.960000\n",
      "epoch = 4870 loss = 0.182614 score = 0.960000\n",
      "epoch = 4880 loss = 0.182450 score = 0.960000\n",
      "epoch = 4890 loss = 0.182287 score = 0.960000\n",
      "epoch = 4900 loss = 0.182124 score = 0.960000\n",
      "epoch = 4910 loss = 0.181962 score = 0.960000\n",
      "epoch = 4920 loss = 0.181800 score = 0.960000\n",
      "epoch = 4930 loss = 0.181639 score = 0.960000\n",
      "epoch = 4940 loss = 0.181478 score = 0.960000\n",
      "epoch = 4950 loss = 0.181318 score = 0.960000\n",
      "epoch = 4960 loss = 0.181159 score = 0.960000\n",
      "epoch = 4970 loss = 0.181000 score = 0.960000\n",
      "epoch = 4980 loss = 0.180841 score = 0.960000\n",
      "epoch = 4990 loss = 0.180683 score = 0.960000\n",
      "epoch = 5000 loss = 0.180526 score = 0.960000\n",
      "epoch = 5010 loss = 0.180369 score = 0.960000\n",
      "epoch = 5020 loss = 0.180212 score = 0.960000\n",
      "epoch = 5030 loss = 0.180056 score = 0.960000\n",
      "epoch = 5040 loss = 0.179901 score = 0.960000\n",
      "epoch = 5050 loss = 0.179746 score = 0.960000\n",
      "epoch = 5060 loss = 0.179591 score = 0.960000\n",
      "epoch = 5070 loss = 0.179437 score = 0.960000\n",
      "epoch = 5080 loss = 0.179284 score = 0.960000\n",
      "epoch = 5090 loss = 0.179131 score = 0.960000\n",
      "epoch = 5100 loss = 0.178978 score = 0.960000\n",
      "epoch = 5110 loss = 0.178826 score = 0.960000\n",
      "epoch = 5120 loss = 0.178675 score = 0.960000\n",
      "epoch = 5130 loss = 0.178524 score = 0.960000\n",
      "epoch = 5140 loss = 0.178373 score = 0.960000\n",
      "epoch = 5150 loss = 0.178223 score = 0.960000\n",
      "epoch = 5160 loss = 0.178073 score = 0.960000\n",
      "epoch = 5170 loss = 0.177924 score = 0.960000\n",
      "epoch = 5180 loss = 0.177776 score = 0.960000\n",
      "epoch = 5190 loss = 0.177627 score = 0.960000\n",
      "epoch = 5200 loss = 0.177480 score = 0.960000\n",
      "epoch = 5210 loss = 0.177332 score = 0.960000\n",
      "epoch = 5220 loss = 0.177186 score = 0.960000\n",
      "epoch = 5230 loss = 0.177039 score = 0.960000\n",
      "epoch = 5240 loss = 0.176893 score = 0.960000\n",
      "epoch = 5250 loss = 0.176748 score = 0.960000\n",
      "epoch = 5260 loss = 0.176603 score = 0.960000\n",
      "epoch = 5270 loss = 0.176459 score = 0.960000\n",
      "epoch = 5280 loss = 0.176314 score = 0.960000\n",
      "epoch = 5290 loss = 0.176171 score = 0.960000\n",
      "epoch = 5300 loss = 0.176028 score = 0.960000\n",
      "epoch = 5310 loss = 0.175885 score = 0.960000\n",
      "epoch = 5320 loss = 0.175743 score = 0.960000\n",
      "epoch = 5330 loss = 0.175601 score = 0.960000\n",
      "epoch = 5340 loss = 0.175459 score = 0.960000\n",
      "epoch = 5350 loss = 0.175318 score = 0.960000\n",
      "epoch = 5360 loss = 0.175178 score = 0.960000\n",
      "epoch = 5370 loss = 0.175038 score = 0.960000\n",
      "epoch = 5380 loss = 0.174898 score = 0.960000\n",
      "epoch = 5390 loss = 0.174759 score = 0.960000\n",
      "epoch = 5400 loss = 0.174620 score = 0.960000\n",
      "epoch = 5410 loss = 0.174482 score = 0.960000\n",
      "epoch = 5420 loss = 0.174344 score = 0.960000\n",
      "epoch = 5430 loss = 0.174206 score = 0.960000\n",
      "epoch = 5440 loss = 0.174069 score = 0.960000\n",
      "epoch = 5450 loss = 0.173932 score = 0.960000\n",
      "epoch = 5460 loss = 0.173796 score = 0.960000\n",
      "epoch = 5470 loss = 0.173660 score = 0.960000\n",
      "epoch = 5480 loss = 0.173524 score = 0.960000\n",
      "epoch = 5490 loss = 0.173389 score = 0.960000\n",
      "epoch = 5500 loss = 0.173255 score = 0.960000\n",
      "epoch = 5510 loss = 0.173120 score = 0.960000\n",
      "epoch = 5520 loss = 0.172987 score = 0.960000\n",
      "epoch = 5530 loss = 0.172853 score = 0.960000\n",
      "epoch = 5540 loss = 0.172720 score = 0.960000\n",
      "epoch = 5550 loss = 0.172587 score = 0.960000\n",
      "epoch = 5560 loss = 0.172455 score = 0.960000\n",
      "epoch = 5570 loss = 0.172323 score = 0.960000\n",
      "epoch = 5580 loss = 0.172192 score = 0.960000\n",
      "epoch = 5590 loss = 0.172061 score = 0.960000\n",
      "epoch = 5600 loss = 0.171930 score = 0.960000\n",
      "epoch = 5610 loss = 0.171800 score = 0.960000\n",
      "epoch = 5620 loss = 0.171670 score = 0.960000\n",
      "epoch = 5630 loss = 0.171540 score = 0.960000\n",
      "epoch = 5640 loss = 0.171411 score = 0.960000\n",
      "epoch = 5650 loss = 0.171282 score = 0.960000\n",
      "epoch = 5660 loss = 0.171154 score = 0.960000\n",
      "epoch = 5670 loss = 0.171026 score = 0.960000\n",
      "epoch = 5680 loss = 0.170898 score = 0.960000\n",
      "epoch = 5690 loss = 0.170771 score = 0.960000\n",
      "epoch = 5700 loss = 0.170644 score = 0.960000\n",
      "epoch = 5710 loss = 0.170517 score = 0.960000\n",
      "epoch = 5720 loss = 0.170391 score = 0.960000\n",
      "epoch = 5730 loss = 0.170265 score = 0.960000\n",
      "epoch = 5740 loss = 0.170140 score = 0.960000\n",
      "epoch = 5750 loss = 0.170015 score = 0.960000\n",
      "epoch = 5760 loss = 0.169890 score = 0.960000\n",
      "epoch = 5770 loss = 0.169766 score = 0.960000\n",
      "epoch = 5780 loss = 0.169642 score = 0.960000\n",
      "epoch = 5790 loss = 0.169518 score = 0.960000\n",
      "epoch = 5800 loss = 0.169395 score = 0.960000\n",
      "epoch = 5810 loss = 0.169272 score = 0.960000\n",
      "epoch = 5820 loss = 0.169149 score = 0.960000\n",
      "epoch = 5830 loss = 0.169027 score = 0.960000\n",
      "epoch = 5840 loss = 0.168905 score = 0.960000\n",
      "epoch = 5850 loss = 0.168784 score = 0.960000\n",
      "epoch = 5860 loss = 0.168663 score = 0.960000\n",
      "epoch = 5870 loss = 0.168542 score = 0.960000\n",
      "epoch = 5880 loss = 0.168421 score = 0.960000\n",
      "epoch = 5890 loss = 0.168301 score = 0.960000\n",
      "epoch = 5900 loss = 0.168181 score = 0.960000\n",
      "epoch = 5910 loss = 0.168062 score = 0.960000\n",
      "epoch = 5920 loss = 0.167943 score = 0.960000\n",
      "epoch = 5930 loss = 0.167824 score = 0.960000\n",
      "epoch = 5940 loss = 0.167705 score = 0.960000\n",
      "epoch = 5950 loss = 0.167587 score = 0.960000\n",
      "epoch = 5960 loss = 0.167470 score = 0.960000\n",
      "epoch = 5970 loss = 0.167352 score = 0.960000\n",
      "epoch = 5980 loss = 0.167235 score = 0.960000\n",
      "epoch = 5990 loss = 0.167118 score = 0.960000\n",
      "epoch = 6000 loss = 0.167002 score = 0.960000\n",
      "epoch = 6010 loss = 0.166886 score = 0.960000\n",
      "epoch = 6020 loss = 0.166770 score = 0.960000\n",
      "epoch = 6030 loss = 0.166654 score = 0.960000\n",
      "epoch = 6040 loss = 0.166539 score = 0.960000\n",
      "epoch = 6050 loss = 0.166424 score = 0.960000\n",
      "epoch = 6060 loss = 0.166310 score = 0.960000\n",
      "epoch = 6070 loss = 0.166195 score = 0.960000\n",
      "epoch = 6080 loss = 0.166082 score = 0.960000\n",
      "epoch = 6090 loss = 0.165968 score = 0.960000\n",
      "epoch = 6100 loss = 0.165855 score = 0.960000\n",
      "epoch = 6110 loss = 0.165742 score = 0.960000\n",
      "epoch = 6120 loss = 0.165629 score = 0.960000\n",
      "epoch = 6130 loss = 0.165517 score = 0.960000\n",
      "epoch = 6140 loss = 0.165405 score = 0.960000\n",
      "epoch = 6150 loss = 0.165293 score = 0.960000\n",
      "epoch = 6160 loss = 0.165182 score = 0.960000\n",
      "epoch = 6170 loss = 0.165070 score = 0.960000\n",
      "epoch = 6180 loss = 0.164960 score = 0.960000\n",
      "epoch = 6190 loss = 0.164849 score = 0.960000\n",
      "epoch = 6200 loss = 0.164739 score = 0.960000\n",
      "epoch = 6210 loss = 0.164629 score = 0.960000\n",
      "epoch = 6220 loss = 0.164519 score = 0.960000\n",
      "epoch = 6230 loss = 0.164410 score = 0.960000\n",
      "epoch = 6240 loss = 0.164301 score = 0.960000\n",
      "epoch = 6250 loss = 0.164192 score = 0.960000\n",
      "epoch = 6260 loss = 0.164084 score = 0.960000\n",
      "epoch = 6270 loss = 0.163976 score = 0.960000\n",
      "epoch = 6280 loss = 0.163868 score = 0.960000\n",
      "epoch = 6290 loss = 0.163760 score = 0.960000\n",
      "epoch = 6300 loss = 0.163653 score = 0.960000\n",
      "epoch = 6310 loss = 0.163546 score = 0.960000\n",
      "epoch = 6320 loss = 0.163439 score = 0.960000\n",
      "epoch = 6330 loss = 0.163333 score = 0.960000\n",
      "epoch = 6340 loss = 0.163227 score = 0.960000\n",
      "epoch = 6350 loss = 0.163121 score = 0.960000\n",
      "epoch = 6360 loss = 0.163016 score = 0.960000\n",
      "epoch = 6370 loss = 0.162910 score = 0.960000\n",
      "epoch = 6380 loss = 0.162805 score = 0.960000\n",
      "epoch = 6390 loss = 0.162701 score = 0.960000\n",
      "epoch = 6400 loss = 0.162596 score = 0.960000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 6410 loss = 0.162492 score = 0.960000\n",
      "epoch = 6420 loss = 0.162388 score = 0.960000\n",
      "epoch = 6430 loss = 0.162285 score = 0.960000\n",
      "epoch = 6440 loss = 0.162181 score = 0.960000\n",
      "epoch = 6450 loss = 0.162078 score = 0.960000\n",
      "epoch = 6460 loss = 0.161975 score = 0.960000\n",
      "epoch = 6470 loss = 0.161873 score = 0.960000\n",
      "epoch = 6480 loss = 0.161771 score = 0.960000\n",
      "epoch = 6490 loss = 0.161669 score = 0.960000\n",
      "epoch = 6500 loss = 0.161567 score = 0.960000\n",
      "epoch = 6510 loss = 0.161465 score = 0.960000\n",
      "epoch = 6520 loss = 0.161364 score = 0.960000\n",
      "epoch = 6530 loss = 0.161263 score = 0.960000\n",
      "epoch = 6540 loss = 0.161163 score = 0.960000\n",
      "epoch = 6550 loss = 0.161062 score = 0.960000\n",
      "epoch = 6560 loss = 0.160962 score = 0.960000\n",
      "epoch = 6570 loss = 0.160862 score = 0.960000\n",
      "epoch = 6580 loss = 0.160763 score = 0.960000\n",
      "epoch = 6590 loss = 0.160663 score = 0.960000\n",
      "epoch = 6600 loss = 0.160564 score = 0.960000\n",
      "epoch = 6610 loss = 0.160465 score = 0.960000\n",
      "epoch = 6620 loss = 0.160367 score = 0.960000\n",
      "epoch = 6630 loss = 0.160268 score = 0.960000\n",
      "epoch = 6640 loss = 0.160170 score = 0.960000\n",
      "epoch = 6650 loss = 0.160072 score = 0.960000\n",
      "epoch = 6660 loss = 0.159975 score = 0.960000\n",
      "epoch = 6670 loss = 0.159877 score = 0.960000\n",
      "epoch = 6680 loss = 0.159780 score = 0.960000\n",
      "epoch = 6690 loss = 0.159684 score = 0.960000\n",
      "epoch = 6700 loss = 0.159587 score = 0.960000\n",
      "epoch = 6710 loss = 0.159491 score = 0.960000\n",
      "epoch = 6720 loss = 0.159395 score = 0.960000\n",
      "epoch = 6730 loss = 0.159299 score = 0.960000\n",
      "epoch = 6740 loss = 0.159203 score = 0.960000\n",
      "epoch = 6750 loss = 0.159108 score = 0.960000\n",
      "epoch = 6760 loss = 0.159013 score = 0.960000\n",
      "epoch = 6770 loss = 0.158918 score = 0.960000\n",
      "epoch = 6780 loss = 0.158823 score = 0.960000\n",
      "epoch = 6790 loss = 0.158729 score = 0.960000\n",
      "epoch = 6800 loss = 0.158634 score = 0.960000\n",
      "epoch = 6810 loss = 0.158541 score = 0.960000\n",
      "epoch = 6820 loss = 0.158447 score = 0.960000\n",
      "epoch = 6830 loss = 0.158353 score = 0.960000\n",
      "epoch = 6840 loss = 0.158260 score = 0.960000\n",
      "epoch = 6850 loss = 0.158167 score = 0.960000\n",
      "epoch = 6860 loss = 0.158074 score = 0.960000\n",
      "epoch = 6870 loss = 0.157982 score = 0.960000\n",
      "epoch = 6880 loss = 0.157890 score = 0.960000\n",
      "epoch = 6890 loss = 0.157797 score = 0.960000\n",
      "epoch = 6900 loss = 0.157706 score = 0.960000\n",
      "epoch = 6910 loss = 0.157614 score = 0.960000\n",
      "epoch = 6920 loss = 0.157523 score = 0.960000\n",
      "epoch = 6930 loss = 0.157431 score = 0.960000\n",
      "epoch = 6940 loss = 0.157341 score = 0.960000\n",
      "epoch = 6950 loss = 0.157250 score = 0.960000\n",
      "epoch = 6960 loss = 0.157159 score = 0.960000\n",
      "epoch = 6970 loss = 0.157069 score = 0.960000\n",
      "epoch = 6980 loss = 0.156979 score = 0.960000\n",
      "epoch = 6990 loss = 0.156889 score = 0.960000\n",
      "epoch = 7000 loss = 0.156800 score = 0.960000\n",
      "epoch = 7010 loss = 0.156710 score = 0.960000\n",
      "epoch = 7020 loss = 0.156621 score = 0.960000\n",
      "epoch = 7030 loss = 0.156532 score = 0.960000\n",
      "epoch = 7040 loss = 0.156443 score = 0.960000\n",
      "epoch = 7050 loss = 0.156355 score = 0.960000\n",
      "epoch = 7060 loss = 0.156267 score = 0.960000\n",
      "epoch = 7070 loss = 0.156179 score = 0.960000\n",
      "epoch = 7080 loss = 0.156091 score = 0.960000\n",
      "epoch = 7090 loss = 0.156003 score = 0.960000\n",
      "epoch = 7100 loss = 0.155916 score = 0.960000\n",
      "epoch = 7110 loss = 0.155828 score = 0.960000\n",
      "epoch = 7120 loss = 0.155741 score = 0.960000\n",
      "epoch = 7130 loss = 0.155655 score = 0.960000\n",
      "epoch = 7140 loss = 0.155568 score = 0.960000\n",
      "epoch = 7150 loss = 0.155482 score = 0.960000\n",
      "epoch = 7160 loss = 0.155395 score = 0.960000\n",
      "epoch = 7170 loss = 0.155309 score = 0.960000\n",
      "epoch = 7180 loss = 0.155224 score = 0.960000\n",
      "epoch = 7190 loss = 0.155138 score = 0.960000\n",
      "epoch = 7200 loss = 0.155053 score = 0.960000\n",
      "epoch = 7210 loss = 0.154968 score = 0.960000\n",
      "epoch = 7220 loss = 0.154883 score = 0.960000\n",
      "epoch = 7230 loss = 0.154798 score = 0.960000\n",
      "epoch = 7240 loss = 0.154713 score = 0.960000\n",
      "epoch = 7250 loss = 0.154629 score = 0.960000\n",
      "epoch = 7260 loss = 0.154545 score = 0.960000\n",
      "epoch = 7270 loss = 0.154461 score = 0.960000\n",
      "epoch = 7280 loss = 0.154377 score = 0.960000\n",
      "epoch = 7290 loss = 0.154294 score = 0.960000\n",
      "epoch = 7300 loss = 0.154210 score = 0.960000\n",
      "epoch = 7310 loss = 0.154127 score = 0.960000\n",
      "epoch = 7320 loss = 0.154044 score = 0.960000\n",
      "epoch = 7330 loss = 0.153962 score = 0.960000\n",
      "epoch = 7340 loss = 0.153879 score = 0.960000\n",
      "epoch = 7350 loss = 0.153797 score = 0.960000\n",
      "epoch = 7360 loss = 0.153714 score = 0.960000\n",
      "epoch = 7370 loss = 0.153632 score = 0.960000\n",
      "epoch = 7380 loss = 0.153551 score = 0.960000\n",
      "epoch = 7390 loss = 0.153469 score = 0.960000\n",
      "epoch = 7400 loss = 0.153388 score = 0.960000\n",
      "epoch = 7410 loss = 0.153307 score = 0.960000\n",
      "epoch = 7420 loss = 0.153225 score = 0.960000\n",
      "epoch = 7430 loss = 0.153145 score = 0.960000\n",
      "epoch = 7440 loss = 0.153064 score = 0.960000\n",
      "epoch = 7450 loss = 0.152984 score = 0.960000\n",
      "epoch = 7460 loss = 0.152903 score = 0.960000\n",
      "epoch = 7470 loss = 0.152823 score = 0.960000\n",
      "epoch = 7480 loss = 0.152743 score = 0.960000\n",
      "epoch = 7490 loss = 0.152664 score = 0.960000\n",
      "epoch = 7500 loss = 0.152584 score = 0.960000\n",
      "epoch = 7510 loss = 0.152505 score = 0.960000\n",
      "epoch = 7520 loss = 0.152426 score = 0.960000\n",
      "epoch = 7530 loss = 0.152347 score = 0.960000\n",
      "epoch = 7540 loss = 0.152268 score = 0.960000\n",
      "epoch = 7550 loss = 0.152189 score = 0.960000\n",
      "epoch = 7560 loss = 0.152111 score = 0.960000\n",
      "epoch = 7570 loss = 0.152033 score = 0.960000\n",
      "epoch = 7580 loss = 0.151955 score = 0.960000\n",
      "epoch = 7590 loss = 0.151877 score = 0.960000\n",
      "epoch = 7600 loss = 0.151799 score = 0.960000\n",
      "epoch = 7610 loss = 0.151721 score = 0.960000\n",
      "epoch = 7620 loss = 0.151644 score = 0.960000\n",
      "epoch = 7630 loss = 0.151567 score = 0.960000\n",
      "epoch = 7640 loss = 0.151490 score = 0.960000\n",
      "epoch = 7650 loss = 0.151413 score = 0.960000\n",
      "epoch = 7660 loss = 0.151336 score = 0.960000\n",
      "epoch = 7670 loss = 0.151260 score = 0.960000\n",
      "epoch = 7680 loss = 0.151184 score = 0.960000\n",
      "epoch = 7690 loss = 0.151107 score = 0.960000\n",
      "epoch = 7700 loss = 0.151031 score = 0.960000\n",
      "epoch = 7710 loss = 0.150956 score = 0.960000\n",
      "epoch = 7720 loss = 0.150880 score = 0.960000\n",
      "epoch = 7730 loss = 0.150805 score = 0.960000\n",
      "epoch = 7740 loss = 0.150729 score = 0.960000\n",
      "epoch = 7750 loss = 0.150654 score = 0.960000\n",
      "epoch = 7760 loss = 0.150579 score = 0.960000\n",
      "epoch = 7770 loss = 0.150505 score = 0.960000\n",
      "epoch = 7780 loss = 0.150430 score = 0.960000\n",
      "epoch = 7790 loss = 0.150356 score = 0.960000\n",
      "epoch = 7800 loss = 0.150281 score = 0.960000\n",
      "epoch = 7810 loss = 0.150207 score = 0.960000\n",
      "epoch = 7820 loss = 0.150133 score = 0.960000\n",
      "epoch = 7830 loss = 0.150059 score = 0.960000\n",
      "epoch = 7840 loss = 0.149986 score = 0.960000\n",
      "epoch = 7850 loss = 0.149912 score = 0.960000\n",
      "epoch = 7860 loss = 0.149839 score = 0.960000\n",
      "epoch = 7870 loss = 0.149766 score = 0.960000\n",
      "epoch = 7880 loss = 0.149693 score = 0.960000\n",
      "epoch = 7890 loss = 0.149620 score = 0.960000\n",
      "epoch = 7900 loss = 0.149548 score = 0.960000\n",
      "epoch = 7910 loss = 0.149475 score = 0.960000\n",
      "epoch = 7920 loss = 0.149403 score = 0.960000\n",
      "epoch = 7930 loss = 0.149331 score = 0.960000\n",
      "epoch = 7940 loss = 0.149259 score = 0.960000\n",
      "epoch = 7950 loss = 0.149187 score = 0.960000\n",
      "epoch = 7960 loss = 0.149115 score = 0.960000\n",
      "epoch = 7970 loss = 0.149044 score = 0.960000\n",
      "epoch = 7980 loss = 0.148972 score = 0.960000\n",
      "epoch = 7990 loss = 0.148901 score = 0.960000\n",
      "epoch = 8000 loss = 0.148830 score = 0.960000\n",
      "epoch = 8010 loss = 0.148759 score = 0.960000\n",
      "epoch = 8020 loss = 0.148688 score = 0.960000\n",
      "epoch = 8030 loss = 0.148618 score = 0.960000\n",
      "epoch = 8040 loss = 0.148547 score = 0.960000\n",
      "epoch = 8050 loss = 0.148477 score = 0.960000\n",
      "epoch = 8060 loss = 0.148407 score = 0.960000\n",
      "epoch = 8070 loss = 0.148337 score = 0.960000\n",
      "epoch = 8080 loss = 0.148267 score = 0.960000\n",
      "epoch = 8090 loss = 0.148197 score = 0.960000\n",
      "epoch = 8100 loss = 0.148128 score = 0.960000\n",
      "epoch = 8110 loss = 0.148059 score = 0.960000\n",
      "epoch = 8120 loss = 0.147989 score = 0.960000\n",
      "epoch = 8130 loss = 0.147920 score = 0.960000\n",
      "epoch = 8140 loss = 0.147851 score = 0.960000\n",
      "epoch = 8150 loss = 0.147783 score = 0.960000\n",
      "epoch = 8160 loss = 0.147714 score = 0.960000\n",
      "epoch = 8170 loss = 0.147646 score = 0.960000\n",
      "epoch = 8180 loss = 0.147577 score = 0.960000\n",
      "epoch = 8190 loss = 0.147509 score = 0.960000\n",
      "epoch = 8200 loss = 0.147441 score = 0.960000\n",
      "epoch = 8210 loss = 0.147373 score = 0.960000\n",
      "epoch = 8220 loss = 0.147305 score = 0.960000\n",
      "epoch = 8230 loss = 0.147238 score = 0.960000\n",
      "epoch = 8240 loss = 0.147170 score = 0.960000\n",
      "epoch = 8250 loss = 0.147103 score = 0.960000\n",
      "epoch = 8260 loss = 0.147036 score = 0.960000\n",
      "epoch = 8270 loss = 0.146969 score = 0.960000\n",
      "epoch = 8280 loss = 0.146902 score = 0.960000\n",
      "epoch = 8290 loss = 0.146835 score = 0.960000\n",
      "epoch = 8300 loss = 0.146769 score = 0.960000\n",
      "epoch = 8310 loss = 0.146702 score = 0.960000\n",
      "epoch = 8320 loss = 0.146636 score = 0.960000\n",
      "epoch = 8330 loss = 0.146570 score = 0.960000\n",
      "epoch = 8340 loss = 0.146504 score = 0.960000\n",
      "epoch = 8350 loss = 0.146438 score = 0.960000\n",
      "epoch = 8360 loss = 0.146372 score = 0.960000\n",
      "epoch = 8370 loss = 0.146306 score = 0.960000\n",
      "epoch = 8380 loss = 0.146241 score = 0.960000\n",
      "epoch = 8390 loss = 0.146175 score = 0.960000\n",
      "epoch = 8400 loss = 0.146110 score = 0.960000\n",
      "epoch = 8410 loss = 0.146045 score = 0.960000\n",
      "epoch = 8420 loss = 0.145980 score = 0.960000\n",
      "epoch = 8430 loss = 0.145915 score = 0.960000\n",
      "epoch = 8440 loss = 0.145851 score = 0.960000\n",
      "epoch = 8450 loss = 0.145786 score = 0.960000\n",
      "epoch = 8460 loss = 0.145722 score = 0.960000\n",
      "epoch = 8470 loss = 0.145658 score = 0.960000\n",
      "epoch = 8480 loss = 0.145593 score = 0.960000\n",
      "epoch = 8490 loss = 0.145529 score = 0.960000\n",
      "epoch = 8500 loss = 0.145466 score = 0.960000\n",
      "epoch = 8510 loss = 0.145402 score = 0.960000\n",
      "epoch = 8520 loss = 0.145338 score = 0.960000\n",
      "epoch = 8530 loss = 0.145275 score = 0.960000\n",
      "epoch = 8540 loss = 0.145211 score = 0.960000\n",
      "epoch = 8550 loss = 0.145148 score = 0.960000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 8560 loss = 0.145085 score = 0.960000\n",
      "epoch = 8570 loss = 0.145022 score = 0.960000\n",
      "epoch = 8580 loss = 0.144959 score = 0.960000\n",
      "epoch = 8590 loss = 0.144897 score = 0.960000\n",
      "epoch = 8600 loss = 0.144834 score = 0.960000\n",
      "epoch = 8610 loss = 0.144772 score = 0.960000\n",
      "epoch = 8620 loss = 0.144709 score = 0.960000\n",
      "epoch = 8630 loss = 0.144647 score = 0.960000\n",
      "epoch = 8640 loss = 0.144585 score = 0.960000\n",
      "epoch = 8650 loss = 0.144523 score = 0.960000\n",
      "epoch = 8660 loss = 0.144462 score = 0.960000\n",
      "epoch = 8670 loss = 0.144400 score = 0.960000\n",
      "epoch = 8680 loss = 0.144338 score = 0.960000\n",
      "epoch = 8690 loss = 0.144277 score = 0.960000\n",
      "epoch = 8700 loss = 0.144216 score = 0.960000\n",
      "epoch = 8710 loss = 0.144155 score = 0.960000\n",
      "epoch = 8720 loss = 0.144093 score = 0.960000\n",
      "epoch = 8730 loss = 0.144033 score = 0.960000\n",
      "epoch = 8740 loss = 0.143972 score = 0.960000\n",
      "epoch = 8750 loss = 0.143911 score = 0.960000\n",
      "epoch = 8760 loss = 0.143851 score = 0.960000\n",
      "epoch = 8770 loss = 0.143790 score = 0.960000\n",
      "epoch = 8780 loss = 0.143730 score = 0.960000\n",
      "epoch = 8790 loss = 0.143670 score = 0.960000\n",
      "epoch = 8800 loss = 0.143610 score = 0.960000\n",
      "epoch = 8810 loss = 0.143550 score = 0.960000\n",
      "epoch = 8820 loss = 0.143490 score = 0.960000\n",
      "epoch = 8830 loss = 0.143430 score = 0.960000\n",
      "epoch = 8840 loss = 0.143371 score = 0.960000\n",
      "epoch = 8850 loss = 0.143311 score = 0.960000\n",
      "epoch = 8860 loss = 0.143252 score = 0.960000\n",
      "epoch = 8870 loss = 0.143193 score = 0.960000\n",
      "epoch = 8880 loss = 0.143133 score = 0.960000\n",
      "epoch = 8890 loss = 0.143074 score = 0.960000\n",
      "epoch = 8900 loss = 0.143016 score = 0.960000\n",
      "epoch = 8910 loss = 0.142957 score = 0.960000\n",
      "epoch = 8920 loss = 0.142898 score = 0.960000\n",
      "epoch = 8930 loss = 0.142840 score = 0.960000\n",
      "epoch = 8940 loss = 0.142781 score = 0.960000\n",
      "epoch = 8950 loss = 0.142723 score = 0.960000\n",
      "epoch = 8960 loss = 0.142665 score = 0.960000\n",
      "epoch = 8970 loss = 0.142607 score = 0.960000\n",
      "epoch = 8980 loss = 0.142549 score = 0.960000\n",
      "epoch = 8990 loss = 0.142491 score = 0.960000\n",
      "epoch = 9000 loss = 0.142433 score = 0.960000\n",
      "epoch = 9010 loss = 0.142376 score = 0.960000\n",
      "epoch = 9020 loss = 0.142318 score = 0.960000\n",
      "epoch = 9030 loss = 0.142261 score = 0.960000\n",
      "epoch = 9040 loss = 0.142204 score = 0.960000\n",
      "epoch = 9050 loss = 0.142147 score = 0.960000\n",
      "epoch = 9060 loss = 0.142089 score = 0.960000\n",
      "epoch = 9070 loss = 0.142033 score = 0.960000\n",
      "epoch = 9080 loss = 0.141976 score = 0.960000\n",
      "epoch = 9090 loss = 0.141919 score = 0.960000\n",
      "epoch = 9100 loss = 0.141862 score = 0.960000\n",
      "epoch = 9110 loss = 0.141806 score = 0.960000\n",
      "epoch = 9120 loss = 0.141750 score = 0.960000\n",
      "epoch = 9130 loss = 0.141693 score = 0.960000\n",
      "epoch = 9140 loss = 0.141637 score = 0.960000\n",
      "epoch = 9150 loss = 0.141581 score = 0.960000\n",
      "epoch = 9160 loss = 0.141525 score = 0.960000\n",
      "epoch = 9170 loss = 0.141469 score = 0.960000\n",
      "epoch = 9180 loss = 0.141414 score = 0.960000\n",
      "epoch = 9190 loss = 0.141358 score = 0.960000\n",
      "epoch = 9200 loss = 0.141303 score = 0.960000\n",
      "epoch = 9210 loss = 0.141247 score = 0.960000\n",
      "epoch = 9220 loss = 0.141192 score = 0.960000\n",
      "epoch = 9230 loss = 0.141137 score = 0.960000\n",
      "epoch = 9240 loss = 0.141082 score = 0.960000\n",
      "epoch = 9250 loss = 0.141027 score = 0.960000\n",
      "epoch = 9260 loss = 0.140972 score = 0.960000\n",
      "epoch = 9270 loss = 0.140917 score = 0.960000\n",
      "epoch = 9280 loss = 0.140863 score = 0.960000\n",
      "epoch = 9290 loss = 0.140808 score = 0.960000\n",
      "epoch = 9300 loss = 0.140754 score = 0.960000\n",
      "epoch = 9310 loss = 0.140699 score = 0.960000\n",
      "epoch = 9320 loss = 0.140645 score = 0.960000\n",
      "epoch = 9330 loss = 0.140591 score = 0.960000\n",
      "epoch = 9340 loss = 0.140537 score = 0.960000\n",
      "epoch = 9350 loss = 0.140483 score = 0.960000\n",
      "epoch = 9360 loss = 0.140429 score = 0.960000\n",
      "epoch = 9370 loss = 0.140376 score = 0.960000\n",
      "epoch = 9380 loss = 0.140322 score = 0.960000\n",
      "epoch = 9390 loss = 0.140268 score = 0.960000\n",
      "epoch = 9400 loss = 0.140215 score = 0.960000\n",
      "epoch = 9410 loss = 0.140162 score = 0.960000\n",
      "epoch = 9420 loss = 0.140109 score = 0.960000\n",
      "epoch = 9430 loss = 0.140055 score = 0.960000\n",
      "epoch = 9440 loss = 0.140002 score = 0.960000\n",
      "epoch = 9450 loss = 0.139950 score = 0.960000\n",
      "epoch = 9460 loss = 0.139897 score = 0.960000\n",
      "epoch = 9470 loss = 0.139844 score = 0.960000\n",
      "epoch = 9480 loss = 0.139791 score = 0.960000\n",
      "epoch = 9490 loss = 0.139739 score = 0.960000\n",
      "epoch = 9500 loss = 0.139687 score = 0.960000\n",
      "epoch = 9510 loss = 0.139634 score = 0.960000\n",
      "epoch = 9520 loss = 0.139582 score = 0.960000\n",
      "epoch = 9530 loss = 0.139530 score = 0.960000\n",
      "epoch = 9540 loss = 0.139478 score = 0.960000\n",
      "epoch = 9550 loss = 0.139426 score = 0.960000\n",
      "epoch = 9560 loss = 0.139374 score = 0.960000\n",
      "epoch = 9570 loss = 0.139323 score = 0.960000\n",
      "epoch = 9580 loss = 0.139271 score = 0.960000\n",
      "epoch = 9590 loss = 0.139219 score = 0.960000\n",
      "epoch = 9600 loss = 0.139168 score = 0.960000\n",
      "epoch = 9610 loss = 0.139117 score = 0.960000\n",
      "epoch = 9620 loss = 0.139065 score = 0.960000\n",
      "epoch = 9630 loss = 0.139014 score = 0.960000\n",
      "epoch = 9640 loss = 0.138963 score = 0.960000\n",
      "epoch = 9650 loss = 0.138912 score = 0.960000\n",
      "epoch = 9660 loss = 0.138861 score = 0.960000\n",
      "epoch = 9670 loss = 0.138811 score = 0.960000\n",
      "epoch = 9680 loss = 0.138760 score = 0.960000\n",
      "epoch = 9690 loss = 0.138709 score = 0.960000\n",
      "epoch = 9700 loss = 0.138659 score = 0.960000\n",
      "epoch = 9710 loss = 0.138609 score = 0.960000\n",
      "epoch = 9720 loss = 0.138558 score = 0.960000\n",
      "epoch = 9730 loss = 0.138508 score = 0.960000\n",
      "epoch = 9740 loss = 0.138458 score = 0.960000\n",
      "epoch = 9750 loss = 0.138408 score = 0.960000\n",
      "epoch = 9760 loss = 0.138358 score = 0.960000\n",
      "epoch = 9770 loss = 0.138308 score = 0.960000\n",
      "epoch = 9780 loss = 0.138258 score = 0.960000\n",
      "epoch = 9790 loss = 0.138209 score = 0.960000\n",
      "epoch = 9800 loss = 0.138159 score = 0.960000\n",
      "epoch = 9810 loss = 0.138110 score = 0.960000\n",
      "epoch = 9820 loss = 0.138060 score = 0.960000\n",
      "epoch = 9830 loss = 0.138011 score = 0.960000\n",
      "epoch = 9840 loss = 0.137962 score = 0.960000\n",
      "epoch = 9850 loss = 0.137913 score = 0.960000\n",
      "epoch = 9860 loss = 0.137864 score = 0.960000\n",
      "epoch = 9870 loss = 0.137815 score = 0.960000\n",
      "epoch = 9880 loss = 0.137766 score = 0.960000\n",
      "epoch = 9890 loss = 0.137717 score = 0.960000\n",
      "epoch = 9900 loss = 0.137669 score = 0.960000\n",
      "epoch = 9910 loss = 0.137620 score = 0.960000\n",
      "epoch = 9920 loss = 0.137572 score = 0.960000\n",
      "epoch = 9930 loss = 0.137523 score = 0.960000\n",
      "epoch = 9940 loss = 0.137475 score = 0.960000\n",
      "epoch = 9950 loss = 0.137427 score = 0.960000\n",
      "epoch = 9960 loss = 0.137379 score = 0.960000\n",
      "epoch = 9970 loss = 0.137331 score = 0.960000\n",
      "epoch = 9980 loss = 0.137283 score = 0.960000\n",
      "epoch = 9990 loss = 0.137235 score = 0.960000\n"
     ]
    }
   ],
   "source": [
    "loss_set, update_weight = train(x_train, y_train_one, x_test, y_test, learning_rate, iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First epoch result: Loss:1.091583, Accur：0.266667\n",
      "Final epoch result: Loss:0.137235, Accur：0.960000\n"
     ]
    }
   ],
   "source": [
    "print('First epoch result: Loss:{:f}, Accur：{:f}'.format(loss_set[0,1], loss_set[0,2]))\n",
    "print('Final epoch result: Loss:{:f}, Accur：{:f}'.format(loss_set[-1,1], loss_set[-1,2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot learning curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:19: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x324 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "xmin, xmax, num = 0.01, 10, 100      \n",
    "x = np.linspace(xmin, xmax, num)     \n",
    "\n",
    "# 建立繪圖物件 fig, 大小為 12 * 4.5, 內有 1 列 2 欄的小圖, 兩圖共用 x 軸和 y 軸\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize = (12, 4.5))\n",
    "\n",
    "ax1.plot(loss_set[:,0], loss_set[:,1], 'b')\n",
    "ax1.set_title('iteration vs loss', fontsize=14)\n",
    "ax1.set_xlabel('iteration', fontsize = 16)\n",
    "ax1.set_ylabel('loss', fontsize = 16)\n",
    "ax1.grid(True)\n",
    "\n",
    "ax2.plot(loss_set[:,0], loss_set[:,2], 'b')\n",
    "ax2.set_title('iteration vs accuracy', fontsize=14)\n",
    "ax2.set_xlabel('iteration', fontsize = 16)\n",
    "ax2.set_ylabel('accuracy',  fontsize = 16)\n",
    "ax2.grid(True)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAEbCAYAAADeeCN4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAgAElEQVR4nO3deXhU5dn48e89e3YChBAIGFBQ9kXAHWLdcKm7VbQVsGpta19/9W2t1i7W2sVabWu1rbzWra3iWveloqaIomyCIIuyShAhEMg+2eb5/XFOwsyQbcJkJsm5P9c1V84259zPHJh7nuWcI8YYlFJKqSauZAeglFKqe9HEoJRSKoImBqWUUhE0MSillIqgiUEppVQETQxKKaUiaGJQnSIij4jIy8mOQykVf5oYVGfdAHy9aUZEikTkviTGExMRKRARIyJTkhhDnojUiUi/sGU+ESkRkUoRyUpWbMrZNDGoTjHGlBlj9sd7vyLii/c+u7FzgfeNMXvDlp0PbAEWA5cnJaowDjsfyqaJQXVKeFOSiDwCzAC+a/8KNyJSYK8bLSKviEiFiOwWkSdEZGD0fkTkRyJSDBS3cKxMEakRka9GLT9dROpFZIA9/zMR2SYitSLypYg8dohl/JaIbLR/1W8UkWtaWP+piARFZI+IvCEiHnvdOBF5S0TK7V//q0Tk5KhDnAe8ELXsm8A/gMfs6eiYfCLy67BybhaR/wlbf5SIvCgiZfZxF4vIOHvdQc1/InKbiKwJm2/xfIjI10Vkadh5fFpEBkftq8Vji8h0+zwNjNr+VyLycRunQCWJJgYVDzdg/cJ9GMizX9tFJA9YCKwBpgGnAunACyIS/m9vBjAemAmcEr1zY0w58BJwRdSqK4A3jTG7ReQi4AfAd4ARwDnAks4WSEQuAO4D/giMBf4E/KUpOdlNUPcDvwCOtON+PWwXjwM77XJPBG4DgmH7zwC+QlhiEJHDgEJgPvAccJSITIgK7VHgSuBGYBRW8thvv38QsAgwwGnAZDtGd4zFb+l8+ICfAxOwPtv+wBNhsbd6bGPMQmCTHXfT9i57/u8xxqYSwRijL33F/AIeAV4Omy8C7ova5nbgrahl2VhfHtPC9lMC+Ns53rlANZBhz6cA5cDl9vyNwAbA28H4C+w4prSy/j3goRbKvMievhAoa4qnhfeXA7PbOP4lwMdRy26L+kwfC/9MsRKeAWa2ss9fAdsAX0fOWdgx10Rt05HzcZQdS34Hj/0DYF3Y/JlALdAv2f+W9XXwS2sMqisdDUy3mxUqRaQS2G6vOzxsuzXGmNp29vUaVmK4wJ4/FxDgeXv+aSAAbBGRv4vIJSLiP4TYR2Elh3CLgNH29JtYX4RbRORfIjLbrgU0uQd4UETeFpFbReSoqH1FNCPZv6DnYjUjNfkHcIWIBOz5SUAIeKeVmCdhJa66DpWwdQedDxGZLCIv2E1YFcAye9XQDh77UWC4iBxvz18FPG8i+1dUN6GJQXUlF/AKVlNK+GsEEN7WXdXejowx9cBTHGhOugL4tzGm2l6/HatJ51tYv9bvBpaLSFpcShIWin28Cqzmkq8BnwO3AOvtJhWMMbdhJZHngeOBj0XkKgC7H+JsIvsXTsf6kv2XiDSISANWMuwDXBSn2ENYyTSct4XtIs6H/Rm+gZWYvwFMxWpmAquJqV3GmBLgReAqsUZhnYs2I3VbmhhUvNRxcFv2CmAMsM0YszHqVdGJY/wTOEVERmN9Mf0zfKUxJmiMecUY832sL68xwAmdOA7AuhbeeyKwNux4DcaYt40xt2C1yadhtb83rf/MGHOvMeZsrC/Bq+1VM4BKY8yyA7vmm1j9CtFJ9P840Am9Euv/bHQndpOPgBPbGElUgtX/E25iK9uGOwqrT+HHxpiFxpj1wIAYjw1WWb6Glby/BBZ04NgqCTzJDkD1GluBafZopEqgFKvz8RrgSRG5E+uLaTjWl8P/xpocjDHvi8g2rI7dPcBbTetEZA7Wv+cP7eNfCtQDn7Wz25H2r/Nw64G7gKdFZDnwH6xEdAVW3wIicg5Wc9hCu6wnAxnAOhFJAX6P1by1FcjFSiof2vs/D+vXc1PsOVi/oC8xxjSPELLX/R1YLCKHG2M+FZGnsJqobsBKvPlAgTHmH8BfgOuAp0TkV8A+rAS5zhizEngbuMmuuSy0y3ICLYwEi/I5Vn/A9SJyP1Yz2y+jtmnv2GA1v+3F6sT+rTEm1M5xVbIku5NDXz3zxcGdzyOxRiZVYzW3FNjLRwDPYH1R1GB1EP8Zu5Myej8dOO7t9v7viVp+vn38/VhNIUuBc9rYT4G9n5ZeY+1trgM2YiWYjcA1Ye8/Eautf69drjXAXHudDyt5bcX6Qv0CmAdk2uu3AaeH7etGrOavgzp8sZp+tgG/tuf9wO+AHfa+NwHXh20/BngVKzlWAO83lcdefxvWaKkyrC/zX3Nw5/NB5wMr0W7CGlm1BDjD/qwKO3pse5ufYTVpFST737C+Wn+JfbKUUgkgIpOwEkqOsfpNHEVE/gocYYw5LdmxqNZpU5JSieUFvue0pCDW7T1GY1278LUkh6PaoTUGpVSXE5EirIv9/m6M+V6Sw1Ht0MSglFIqgg5XVUopFaHH9zH079/fFBQUdOq9VVVVpKXF+/qn7k3L7AxaZmc4lDIvX758jzEmp6V1PT4xFBQUsGzZsvY3bEFRURGFhYXxDaib0zI7g5bZGQ6lzPY1QS3SpiSllFIRNDEopZSKoIlBKaVUBE0MSimlImhiUEopFUETg1JKqQiaGJRSSkVwbGJYurWUZz+to6FRbwmvlFLhHJsYPvp8Hy9trifYoIlBKaXCOTYx+D3WUyhr6xuTHIlSSnUvjk0MAa9V9FqtMSilVATHJobmGoMmBqWUiuDgxNBUY9CmJKWUCufcxNDUlFSvNQallArn3MRgNyUFtfNZKaUiODgxaOezUkq1xMGJQTuflVKqJc5NDF7tfFZKqZY4NzF4tPNZKaVa4uDEoE1JSinVEscmhoA2JSmlVIscmxi0xqCUUi1zbGLwaR+DUkq1yLGJwe0S3KJNSUopFS1hiUFEHhKR3SKyppX1IiL3ishGEflYRCZ3dUxeFwS1xqCUUhESWWN4BJjZxvozgRH261rgr10dkNetNQallIqWsMRgjFkIlLaxyXnAY8byAdBHRPK6MiavS7TzWSmloniSHUCYwcD2sPlie9nO6A1F5FqsWgW5ubkUFRV16oBuQmzfsZOion2den9PVFlZ2enPq6fSMjuDljl+ulNi6DBjzDxgHsCUKVNMYWFhp/bjX/QqWX37U1g4JY7RdW9FRUV09vPqqbTMzqBljp/uNCppBzAkbD7fXtZlvG5tSlJKqWjdKTG8CFxpj046FigzxhzUjBRPPpd2PiulVLSENSWJyBNAIdBfRIqBnwNeAGPM34BXgbOAjUA1MLerY9LOZ6WUOljCEoMxZlY76w3w3QSFA9jDVfU6BqWUitCdmpISzqtNSUopdZAeOSopXrwuIRhMcI3hi5VQW5HYY4bps281bHEn7fjJoGV2BieW2Ve7t0v26/DEkOC7q365BubNSNzxWjARYFVSQ0g4LbMzOLHM/UdcB1wU9/06OzEk+pYYpZusv+fdD30OS9xxw6xcuZKJEycm5djJomV2BieWec+nuxnZBft1dmJwSdcnhtLNsPpZwMCO5dayI8+C1L5de9xW7N/WCMNOSsqxk0XL7AxOLHPdtqIu2a/DEwPUNYQwxiAiXXOQ9++DZX8/MN9vBKRkd82xlFIqDhyfGMDqZwh4u6jTqqwYcsfBt/5rzYsLuioJKaVUHDg7MbitL+guSQyv3gR7PrWajw47AVzOGi2hlOq5HH8dA3RBB3SwHJY8YPUv5BwF4y+J7/6VUqoLObvG0JQY4n31c7l9779TfgbjLo7vvpVSqos5OzGENSV12ifPw/PfARNW6wjZ05mDDyE6pZRKDmcnBrvGEKw/hKakzxeDCcEx34pc7s+E/Kmd369SSiWJJgZaqTGUboaa/e3vZPc6yD4MTrs9vsEppVSSODwxNDUlRdUYyorh3smA6diORs6Mb2BKKZVEzk4M9gjSg2oMezcBBk69DXJGtb+jQZPiHJlSSiWPsxNDa6OSyr+w/o46F/odntiglFIqyRx+HUMrTUlNw00zByU4IqWUSj5HJwZfa01J5TsgpS94UxIflFJKJZmjE8OBGkNYYjAGlj2k1yAopRzL4YnB+lsbfh1Ddan1N6VP4gNSSqluwNmJoaWmpPpq6+84vb+RUsqZHJ0YPPbdryNqDA1B6683NfEBKaVUN+DoxCAi+D2uqBpDjfXXG0hOUEoplWSOTgwAAa+bmvAaQ3Ni0BFJSilncnxiSPO5qa4Lb0qyE4NHE4NSypk0Mfg9VNU2HFigTUlKKYdzfGJI9XuoDE8MJeutv9r5rJRyKMcnhnR/VFPS1kXW37QByQlIKaWSzPGJIdUX1ZTUWA+54yCtX/KCUkqpJHJ8Ykj3e6iqC0sMtRWQkZu8gJRSKskcnxjS/G6qasOakmrLwZ+RvICUUirJNDH4ojqfays0MSilHC2hiUFEZorIBhHZKCI3t7B+qIi8IyIficjHInJWV8eU5vdQ1xCivjEE+7ZC5S7wZ3b1YZVSqttKWGIQETdwP3AmMBqYJSKjozb7CfCUMWYScBnwl66OK9V+KEN1bSN8udpaOHBcVx9WKaW6rUTWGKYBG40xm40xdcB84LyobQzQ9HM9C/iiq4NK91tPN62sa7CakQCGHNPVh1VKqW4rkc98HgxsD5svBqK/gW8D/iMi3wPSgFO7Oqg0OzFU14YlBm1KUko5WCITQ0fMAh4xxtwtIscB/xCRscaYiGdvisi1wLUAubm5FBUVdepglZWVbNq9FoCFi5fgLlvFcOC/H67AuLyHUIzuq7KystOfV0+lZXYGLXP8JDIx7ACGhM3n28vCfROYCWCMWSwiAaA/sDt8I2PMPGAewJQpU0xhYWGnAioqKuK40eP444oPOHL0eIa/8wsQNzO+clqn9tcTFBUV0dnPq6fSMjuDljl+EtnHsBQYISLDRMSH1bn8YtQ2nwOnAIjIKCAAlHRlUE1NSbJnLexcBa7uVolSSqnESlhiMMY0ANcDbwDrsEYffSIit4vIufZm/wtcIyKrgCeAOcYY05VxNSWGUIWdfy55pCsPp5RS3V5Cfx4bY14FXo1a9rOw6bXACYmMKc1vDVdtDNodz1mDE3l4pZTqdvTKZ59dYwiWWwv0qmellMM5PjGk+ty4XUJjTVNi0KGqSilnc3xiEBH6pHgZs8vuB/elJzcgpZRKMscnBoCsFC/SWAvi0kd6KqUcTxMDkJXqxd0YhHFfS3YoSimVdJoYgD4pXryhWvCmJDsUpZRKOk0MQJ9UH34TBF9askNRSqmk08QAZAU8BNAag1JKgSYGAPr6Q7gwhDypyQ5FKaWSThMD0N9vPdozKP4kR6KUUsmniQHo67MSQ5XxJTkSpZRKPk0MQB9PPQBVIa0xKKWUJgYgy2PVGCoae+fDeZRSKhaaGIBMu8ZQHtLEoJRSmhiATFcdAKW1+pAepZTSxACk2YlhT607yZEopVTyaWIAXPU1AOwKamJQSiltOwGorwbgy2pJciBKqWj19fUUFxcTDAbb3C4rK4t169YlKKruoSNlDgQC5Ofn4/V2vA9VEwM0J4Yd1VqBUqq7KS4uJiMjg4KCAkRa//FWUVFBRoaznsDYXpmNMezdu5fi4mKGDRvW4f3qNyFAnZ0YKpMch1LqIMFgkH79+rWZFFTLRIR+/fq1W9uKpokBoL6aBvGyq6qRUMgkOxqlVBRNCp3Xmc9OEwNAfTWN7hQaQ4Z91XXJjkYp1c2kpzvrkb+aGADqqwl5rFtul1TWJjkYpZRKLk0MYPUx+KxbbpdUaGJQSrXMGMMPf/hDxo4dy7hx43jyyScB2LlzJ9OnT2fixImMHTuWd999l8bGRubMmdO87R/+8IckR99xMY1KEpEcAGNMiT0/DrgU+MQY80T8w0sAY+CT53D3HwPAzrLYOmmUUonzi5c+Ye0X5S2ua2xsxO2O/Vqk0YMy+flXx3Ro2+eee46VK1eyatUq9uzZw9SpU5k+fTqPP/44Z5xxBrfeeiuNjY1UV1ezcuVKduzYwZo1awDYv39/zLElS6w1hqeArwKISH9gIXAB8DcR+d84x5YYddZQJE9KBiKwY19NkgNSSnVXixYtYtasWbjdbnJzc5kxYwZLly5l6tSpPPzww9x2222sXr2ajIwMhg8fzubNm/ne977H66+/TmZmZrLD77BYr2MYD3xgT18MbDTGTBWR84C7gLvjGVxC1FYA4JpwGQN2+dmxXxODUt1VW7/sk3kdw/Tp01m4cCGvvPIKc+bM4cYbb+TKK69k1apVvPHGG/ztb3/jqaee4qGHHkpKfLGKtcaQAjSN9j8VeNGeXgEMiVdQCWUnBvwZDO6TojUGpVSrTjrpJJ588kkaGxspKSlh4cKFTJs2jW3btpGbm8s111zD1VdfzYoVK9izZw+hUIiLLrqIO+64gxUrViQ7/A6LtcbwGXChiDwLnI5VSwDIBXpOA1q45sSQyeDsVFZt75nFUEp1vQsuuIDFixczYcIERITf/e53DBw4kEcffZS77roLr9dLeno6jz32GDt27GDu3LmEQiEAfvOb3yQ5+o6LNTH8AngCq8noLWPMh/byM4CP4hlYQhgDO5Zb03aN4fU1OwmFDC6XXlCjlLJUVloNJSLCXXfdxV133RWxfvbs2cyePfug9/WkWkK4mBKDMeY5ERkKDAJWha1aADwbz8ASIa1qK/z3JmsmfQCDsz3UNxpKKmvJzQwkNTallEqWmG+iZ4zZBexqmheRI4BVxpgeN87TV1dmTZx2O/Q7nPw9uwHYXlqtiUEp5VgxdT6LyK9FZLY9LSLyJvApsFNEjumKALuSK2Q90pOCEwEY1i8NgC17qpIVklJKJV2so5KuADbY02cCE4FjgceA37b3ZhGZKSIbRGSjiNzcyjZfE5G1IvKJiDweY3wxEWMnBrcfgPzsFLxuYbMmBqWUg8XalJQLFNvTZwFPGWOWiEgpsKytN4qIG7gfOM3ex1IRedEYszZsmxHALcAJxph9IjIgxvhi0lxj8FiJweN2MbRvKptL9P7bSinnirXGsBc4zJ4+HXjLnvYA7Q3jmYZ1QdxmY0wdMB84L2qba4D7jTH7AIwxu2OMLybNicHta142PCedzSVaY1BKOVesNYZngcdF5FOgL/CGvXwisLGd9w4GtofNFwPR/RIjAUTkPcAN3GaMeT16RyJyLXAtQG5uLkVFRbGVwta3xqoZvL9kOXX+LQB4a+rYUlLP2++8g6sX3gO+srKy059XT6Vl7tmysrKoqKhod7vGxsYObdebdLTMwWAwpn8PsSaGG4FtwFDgJmNM00/rPOCvMe6rtXhGAIVAPrBQRMYZYyKuOjPGzAPmAUyZMsUUFhZ26mCfFb8EwPEnFUJqXwB2p23n1S0fM3zcNAr6p3Vqv91ZUVERnf28eiotc8+2bt26Dt3qoqc/2rOhoQGPJ7av5I6WORAIMGnSpA7vN6amJGNMgzHmbmPMDcaYj8KW/8EY82A7b99B5G0z8u1l4YqBF40x9caYLVgjnkbEEmMsovsYAI7Ksz7kdTtbvoOjUsp5zj//fI4++mjGjBnDvHnzAHj99deZPHkyEyZM4JRTTgGsmtrcuXMZN24c48eP59lnrcu7wh/088wzzzBnzhwA5syZw3XXXccxxxzDTTfdxJIlSzjuuOOYNGkSxx9/PBs2WGN9Ghsb+cEPfsDYsWMZP348f/7zn3n77beZNWtW837ffPNNLrjggriUN+brGEQkF/guMBowwFqsfoH2+gOWAiNEZBhWQrgMuDxqm+eBWcDD9t1bRwKbY42xow70MRxIDCNzM3C7hE++KOfMcXlddWilVGe8djN8ubrFVSmNDeCO+SsNBo6DM9seVPnQQw/Rt29fampqmDp1Kueddx7XXHMNCxcuZNiwYZSWlgLwy1/+kqysLFavtmLct29fu4cvLi7m/fffx+12U15ezrvvvovH42HBggX8+Mc/5tlnn2XevHls3bqVlStX4vF4KC0tJTs7m+uuu46SkhJycnJ4+OGHueqqq2IvfwtifR7DCcDrWBe4LbYXXwF8X0TOMMYsbu29xpgGEbkeq1/CDTxkjPlERG4HlhljXrTXnS4ia4FG4IfGmL0xl6qDXKF6EFfEP6aA180ROems1RqDUsp277338u9//xuA7du3M2/ePKZPn86wYcMA6NvXaopesGAB8+fPb35fdnZ2u/u+5JJLmp8jUVZWxuzZs/nss88QEerr65v3e9111zU3NTUd77LLLuOf//wnc+fOZfHixTz22GNxKW+s6fX3WPdKus4YEwIQERfwN6z7Jx3f1puNMa8Cr0Yt+1nYtMHqx7gxxrg6RUx9xIikJmMGZfLepj2JCEEpFYs2ftnXdFEfQ1FREQsWLGDx4sWkpqZSWFjIxIkTWb9+fYf3IWEDWYLByJtEpKUd6Mv86U9/ysknn8y///1vtm7d2m4/0de//nVmzZpFIBDgkksuibmPojWxDledCNzdlBQA7Ol7gI73bHQTYgzIwU98Gj0ok13ltezR5z8r5XhlZWVkZ2eTmprK+vXr+eCDDwgGgyxcuJAtW6zRjE1NSaeddhr3339/83ubmpJyc3NZt24doVCouebR2rEGDx4MwCOPPNK8/LTTTuOBBx6goaEh4nh5eXkMGjSIO+64g7lz58atzLEmhjJgWAvLh9Ejb7ttoIUhqaPzrCcttfYIQaWUc8ycOZOGhgZGjRrFzTffzLHHHktOTg7z5s3jwgsvZMKECVx66aUA/OQnP2Hfvn2MHTuWCRMm8M477wDw29/+lnPOOYfjjz+evLzW+y5vuukmbrnlFiZNmtScBACuvvpqhg4dyvjx45kwYQKPP37gphBXXHEFQ4YMYdSoUXErc6z1jvnA30XkJuB9e9kJwJ1YTUw9jLH6GKKMzc9CBD76fD/TR+YkIS6lVHfh9/t57bXXWlx35plnRsynp6fz6KOPHrTdxRdfzMUXX3zQ8vBaAcBxxx3Hp59+2jx/xx13AODxeLjnnnu45557DtrHokWLuOaaa9otRyxiTQw3YV3h/BAHrnauw7qGocV7H3VnYgwtXbCdGfBy1MBMlm4tTXxQSinVQdOnTycjI4O7747vU5VjfR5DHXCDiNwCHG4v3mSMqY5rVAljWr2Rx9SCbJ5ZXkxDYwiPO9YWN6WU6noLFy7skg73dhODiLzYgW0AMMacG4eYEqzlzDC1oC+PLd7G2p3ljM/vk+CYlFIqeTpSY+iy6wiSzRqV1HJtYGqBNU54yZZSTQxKJZkxJmLIp+o46yqA2LSbGIwx8RsD1e20PCoJYGBWgIJ+qby/aS9XnzQ8wXEppZoEAgH27t1Lv379NDnEyBjD3r17CQRieyJlfK6G6LFa7nxuMmNkDk8u206wvpGA9+DrHZRSXS8/P5/i4mJKSkra3C4YDMb8BdjTdaTMgUCA/Pz8mPbr6MRgNSW1nhgKjxzAo4u3sWRLqQ5bVSpJvF5v860n2lJUVBTTHUR7g64qsw63aaPGcOzwfvg8Loo2tP1LRSmlehOHJ4ZQq53PACk+N8cN78eCdbs61YGjlFI9kaMTQ3tNSQBnj8vj89JqVu8oS1BUSimVXI5ODJa2E8MZYwbidQsvf7wzQfEopVRyOTwxtF9jyEr1ctKIHF75eCehkDYnKaV6P00MbfQxNPnqhDx27K9hxeftP41JKaV6OkcnhtZuohfttNEDSfO5mb90e9cHpZRSSeboxNDWTfTCpfs9nDdpMC+t+oKy6vquD0sppZLI4YkBOpQZgMunDaW2IcSzK4q7OB6llEouRyeGtm6iF23s4CwmDOnDPz/cpp3QSqlezdGJoSOjksJ988RhbC6p4j9rv+zCmJRSKrk0MXSwKQmsi90K+qXyl6JNeiW0UqrXcnRi6MiVz+HcLuFbMw7n4+Iy3tvYax9ToZRyOEcnhlhrDAAXTh5MbqafPyz4VGsNSqleyeGJgQ53Pjfxe9zccMpIlm/bx3/W7uqioJRSKnkcnRjEhGJqSmrytSn5HJ6Txp2vrae+MdQFkSmlVPI4OjFYYk8MHreLm88cxeY9VTz+4eddEJNSSiWPwxNDbJ3P4U4dNYATj+jP79/YwK7yYJzjUkqp5NHEEGMfQxMR4Y7zx1LbGOL2l9bGOS6llEoeRyeGjt5ErzUF/dP4n68cwSurd/LWOu2IVkr1Do5ODB29iV5brp1+OEfmZnDzc6spraqLT1hKKZVEDk8McKiZwedx8YdLJ1JWXc9Nz3ys1zYopXq8hCYGEZkpIhtEZKOI3NzGdheJiBGRKV0aTww30WvL6EGZ3DTzSBas28W/dJSSUqqHS1hiEBE3cD9wJjAamCUio1vYLgO4Afiw66Pq/KikaFedMIyTRvTn9pfWsnL7/rjsUymlkiGRNYZpwEZjzGZjTB0wHzivhe1+CdwJJGAM6KF1PodzuYQ/XTaJnAw/1/1jOSUVtXHZr1JKJZongccaDIQ/G7MYOCZ8AxGZDAwxxrwiIj9sbUcici1wLUBubi5FRUWdCmh0QwPlFTWs6OT7W3LtaMOvPghyxV/e5qapATyu+CSeeKmsrOz059VTaZmdQcscP4lMDG0SERdwDzCnvW2NMfOAeQBTpkwxhYWFnTpm6SoXmalZdPb9rekzdAc3zF/JS7v78IevTcTVjZJDUVFR3Mvb3WmZnUHLHD+JTAw7gCFh8/n2siYZwFigSKx2/4HAiyJyrjFmWZdFFYfO52jnTRxM8b4a7npjAwMy/Nx69kFdKUop1W0lMjEsBUaIyDCshHAZcHnTSmNMGdC/aV5EioAfdGVS6OxN9DriO4WHs7s8yP+9u4UBGQGumT68S46jlFLxlrDEYIxpEJHrgTcAN/CQMeYTEbkdWGaMeTFRsUTqmsQgIvzsq2PYU1nHr15dh8/jYvbxBV1yLKWUiqeE9jEYY14FXo1a9rNWti1MQERdVmMA64lvf7h0IvdWhF4AABTMSURBVPWNIX7+4icYY5hzwrAuO55SSsWDw698js8Fbm3xeVzcd/lkzhiTy20vreXBdzd36fGUUupQOToxHOpN9DqqKTmcNW4gd7yyjt+8to5QSG+doZTqnrrNcNXk6NqmpHBet4s/z5pM37Q1PPDfzewur+XOi8bj8zg6NyuluiGHJ4bEcruEX543loGZAX7/n0/ZXRHkvlmTyU7zJTs0pZRq5uifq9ZN9BJ78ZmIcP1XRvD7SyawdMs+zr1/Eeu/LE9oDEop1RZHJ4ZEdD635uKj85n/rWOprQ9x4V/e59XVO5MSh1JKRdPEkIDO59ZMHprNy987kSMHZvCdf63gthc/IVjfmLR4lFIKHJ4YktGUFG1AZoD51x7LN08cxiPvb+X8+99j4+6KpMaklHI2RyeGZNcYmvg9bn56zmgenjOVkopazvnzIv75wTYd0qqUSgqHJwaS1sfQkpOPGsBrN5zE1IK+/OT5NVz+4Ads21uV7LCUUg7Tfb4Vk6Arb6LXWQMyAzx21TR+e+E4PtlRzhl/XMiD726mUWsPSqkEcXRisHSvxADWkNbLpg3lPzdO54TD+3PHK+s4//73WL5tX7JDU0o5gMMTQ/I7n9uSl5XCg7OncO+sSeyuCHLRX9/nxqdWsrs8AU89VUo5liaGbtTH0BIR4dwJg3j7fwv5TuHhvLxqJyf/voi/Fm3Soa1KqS7Rvb8Vu1iibqIXD2l+DzfNPIr/fH86xx3ejztfX8+Mu97hXx9uo74xlOzwlFK9iKMTQ3dvSmpJQf80Hpw9lSevPZb87FRu/fcaTr3nv7ywcocOb1VKxYXDE0PPdczwfjxz3XE8NGcKKV43N8xfyel/XMgzy4u1BqGUOiSOTgzd4crnQyEifOWoXF79n5P486xJeFzCD55exYzfvcPD722hpk77IJRSsXN0YugJnc8d4XIJX50wiNduOImH50xlcHYKv3hpLSfc+TZ3/2cDX5bpKCalVMc5/HkMPafzuSNEhJOPGsDJRw1g6dZSHvjvJu57ZyN/KdrEzDEDufK4wzBG+yGUUm1zdGLo6U1JbZla0JepBX3ZXlrNPz/Yxvyl23ll9U6GZLi4NrCVcycMJivVm+wwlVLdUM9vR+msDa+TWrOD3lRjaMmQvqncctYoPrjlFO68aBwC/PSFT5j66wV874mPWPhpid5uQykVwbk1hsovqQkMJGXY9GRHkhApPjeXTh3KgMpN5IyczNPLtvPCqi94adUX5GUFuHDyYL46YRBH5mYgvbQWpZTqGOcmhqPn8GFFAYVTCpMdSUKJCGMHZzF2cBY/PnsUC9bu5unl2/lr0Sbuf2cTRwxI55zxeZwzfhBHDEhPdrhKqSRwbmJQ+D1uzh6fx9nj8yipqOX1T77k5VVf8Ke3PuOPCz7jqIEZnD0uj9PHDGRkbrrWJJRyCE0MCoCcDD/fOPYwvnHsYewqD/Lq6p28/PFO7n7zU+5+81Pys1M4dVQup47KZdqwvvg8zu2eUqq308SgDpKbGWDuCcOYe8IwdpUHeWvdbt5at4snlnzOI+9vJcPvYfqRORSOzOGkETkMzAokO2SlVBxpYlBtys0McPkxQ7n8mKHU1DWyaOMe3lq3iwXrdvPKxzsBOGJAOice0Z+TRvTnmOH9SPfrPyulejL9H6w6LMXn5rTRuZw2OpdQyLD+ywoWbSxh0ca9zF9q1SY8LmHS0D4cN7wf04b1Y9LQPqRpolCqR9H/sapTXC5h9KBMRg/K5NrphxOsb2TFtn28u3EPiz7bw33vbCT09kbcLmHsoEymFvRl2jDrorvsNF+yw1dKtUETg4qLgNfN8Uf05/gj+vOjmVARrGfF5/tZuqWUJVtKeeyDbTy4aAsAIwakM3FIHyYM6cPEIX04cmAGXrd2ZivVXWhiUF0iI+BlxsgcZozMAaC2oZGPi8tYsqWU5dv28db63Ty9vBgAv8fF2MFZTMjvw4QhWUwc0oehfVN1eKxSSaKJQSWE3+Nuvn8TgDGG4n01rNy+n1Xb97OqeD+PL9nGQ+9Zz5LI8HsYlWc1VY3Oy2RUXiYjctMJeN3JLIZSjpDQxCAiM4E/AW7gQWPMb6PW3whcDTQAJcBVxphtiYxRJYaIMKRvKkP6pvLVCYMAaGgMsWFXBau2l7F2Zxnrdlbw1LLtVNvPlXC7hCNy0hmVl8HoQZmMzM1gRG4Gg7ICWrtQKo4SlhhExA3cD5wGFANLReRFY8zasM0+AqYYY6pF5NvA74BLExWjSi6P28WYQVmMGZTVvCwUMmwrrWbdznLWflHOup3lfLillOdXftG8TZrPzRED0jliQAYjctMZMSCdEQMyyM9OweXShKFUrBJZY5gGbDTGbAYQkfnAeUBzYjDGvBO2/QfA1xMYn+qGXC5hWP80hvVP46xxec3L91XV8dnuSj7bXcFnuyrZuLuSRRtLeHZFcfM2Aa+Lw3PSSQ8FWV63gYJ+aRT0T6OgXyp903xay1CqFZKoB7eIyMXATGPM1fb8N4BjjDHXt7L9fcCXxpg7Wlh3LXAtQG5u7tHz58/vVEyVlZWkpzvrRnG9vcxV9YadlSF2VIX4ojLEF5WGnZUN7A0K4f/SUzyQm+oiN1XITbP/prrISXWR6aPHJ43efp5bomWOzcknn7zcGDOlpXXdsvNZRL4OTAFmtLTeGDMPmAcwZcoUU1hY2KnjFBUV0dn39lROLfPxJ06neF812/ZWs2VPFVv3VrF1bzVb91SxdFc14Y+k8Htc5GenkJ+dyuDslObpfHs6J93f7ROHU8+zljk+EpkYdgBDwubz7WURRORU4FZghjGmNkGxqV7O53ExPCed4TnpnBy1rq4hRPG+arburaJ4X439qqZ4Xw2rd5RRWlUXsb3f42JwdgqD+1ivgVkB8rICDMxKYWBmgIFZATIDnm6fPJRqTSITw1JghIgMw0oIlwGXh28gIpOAB7CanHYnMDblYOFJoyVVtQ3s2H8gWTQlju2lNazbWc6eyrqD3pPqczcniaa/eVkBcjMD5GWlMCDTT780Hx69sE91QwlLDMaYBhG5HngDa7jqQ8aYT0TkdmCZMeZF4C4gHXja/rX1uTHm3ETFqFRL0vweRuZmMDI3o8X1dQ0hdpUH2VUeZGdZkC/LgnxZbv3dWVbDh1tK2VUepCHqEaoi0DfVR/90PzkZYa90P/0zfOSkB5qX9Unx6ggrlTAJ7WMwxrwKvBq17Gdh06cmMh6l4sHncTVfk9GaUMiwp6rWThZBSipqKamoZU+l9bekspatW6soqailtiF00Ps9LqFfuo+cDD/90vz0TfNFvLJTI+dDCRpUonqnbtn5rFRv43IJAzICDMgIMD6/9e2MMVTWNoQljjpKKoKUNCWQilpKq+rYVFLJvqo6quyL/6IJkL3oTbJTvS0mkOxUH1kpXvqkeslKsV+pXvwevbJcaWJQqlsRETICXjIC3lb7PMIF6xvZV11HaVUd+6rq2VtVy76qOlas/YzMnIHNy7buqWb5tv3sq66jMdR6bSLgddEnxReRLLJSvPSJmreSyoHt0v0efapfL6KJQakeLOB1k5eVQl5WSsTygvptFBaOO2h7YwzlNQ3sr6ljf3U9ZTXWa39NPeU19eyvrjuwrLqe7aXVrLHnq1upnTTxe1xkBLxkBjykBzxkBDxk+L0HpgNeMvwHppuWZwY8pPu9ZAQ8pPrcOpqrG9DEoJSDiIj1qz/Vy2H9YntvXUOoOWlYLzuJVNdTWdtARbCB8mCDPV1PRbCBkopKKoPWusq6Btrr+nAJpPvtJBLwkOa3kkWaz5pO87tJ9XlI87kj5tP9Hj4tbaT/jjJruc9Nqt9DqtetnfadoIlBKdUhPo+reZRUZ4RChqo6K0lUBBuorK2nvGk6eCCZVNY2UB6spzLYQHVdI5W1DewqD1JV20h1XQNVtY3UNR7cQQ/AkkUHLUr1NSUPO6n47aTi85Dic5PidZPqcxPwupvnm/82TYfNp/rcBOz53vocEU0MSqmEcLkO9J8cqrqGEDV1jVTWNVBd20BVXSPvL1nOEUeNocpOHtV1DVTWNjavr6ptaE4spVV1fF5aTbCukZp66xWsbyXZtMHjkoOTSVgSCfjcpIYtCzS/XPg91t+m+YDHjd/rxu8JW9a0vceV0GteNDEopXocn8eFz+MiK/VAktm/yU3hmIGd3mcoZAg2NFJT10h1XSNBO2HU1DVSXd8YkURq6uxX/cHbNv0tq6k/aFlLQ5E7yu0SAp4DycLvdXH6oAYKO73H1mliUEoprBpNqs9Dqs9DjN0vHRYKGWobQgTrGwk2WLWUWvtvsL7RflnLautD9jbh68O2b2gk3buvS+LUxKCUUgniamp68sXnepGioqK47Cda7+w5UUop1WmaGJRSSkXQxKCUUiqCJgallFIRNDEopZSKoIlBKaVUBE0MSimlImhiUEopFUFMD3/Sk4iUANs6+fb+wJ44htMTaJmdQcvsDIdS5sOMMTktrejxieFQiMgyY8yUZMeRSFpmZ9AyO0NXlVmbkpRSSkXQxKCUUiqC0xPDvGQHkARaZmfQMjtDl5TZ0X0MSimlDub0GoNSSqkomhiUUkpFcGxiEJGZIrJBRDaKyM3JjqezRGSIiLwjImtF5BMRucFe3ldE3hSRz+y/2fZyEZF77XJ/LCKTw/Y1297+MxGZnawydZSIuEXkIxF52Z4fJiIf2mV7UkR89nK/Pb/RXl8Qto9b7OUbROSM5JSkY0Skj4g8IyLrRWSdiBzX28+ziHzf/ne9RkSeEJFAbzvPIvKQiOwWkTVhy+J2XkXkaBFZbb/nXhGRdoMyxjjuBbiBTcBwwAesAkYnO65OliUPmGxPZwCfAqOB3wE328tvBu60p88CXgMEOBb40F7eF9hs/822p7OTXb52yn4j8Djwsj3/FHCZPf034Nv29HeAv9nTlwFP2tOj7XPvB4bZ/ybcyS5XG+V9FLjanvYBfXrzeQYGA1uAlLDzO6e3nWdgOjAZWBO2LG7nFVhibyv2e89sN6ZkfyhJOhHHAW+Ezd8C3JLsuOJUtheA04ANQJ69LA/YYE8/AMwK236DvX4W8EDY8ojtutsLyAfeAr4CvGz/o98DeKLPMfAGcJw97bG3k+jzHr5dd3sBWfaXpEQt77Xn2U4M2+0vO499ns/ojecZKIhKDHE5r/a69WHLI7Zr7eXUpqSmf3BNiu1lPZpddZ4EfAjkGmN22qu+BHLt6dbK3tM+kz8CNwEhe74fsN8Y02DPh8ffXDZ7fZm9fU8q8zCgBHjYbj57UETS6MXn2RizA/g98DmwE+u8Lad3n+cm8Tqvg+3p6OVtcmpi6HVEJB14Fvh/xpjy8HXG+qnQa8Yli8g5wG5jzPJkx5JAHqzmhr8aYyYBVVhNDM164XnOBs7DSoqDgDRgZlKDSoJknFenJoYdwJCw+Xx7WY8kIl6spPAvY8xz9uJdIpJnr88DdtvLWyt7T/pMTgDOFZGtwHys5qQ/AX1ExGNvEx5/c9ns9VnAXnpWmYuBYmPMh/b8M1iJojef51OBLcaYEmNMPfAc1rnvzee5SbzO6w57Onp5m5yaGJYCI+zRDT6sjqoXkxxTp9gjDP4OrDPG3BO26kWgaWTCbKy+h6blV9qjG44Fyuwq6xvA6SKSbf9SO91e1u0YY24xxuQbYwqwzt3bxpgrgHeAi+3Nosvc9FlcbG9v7OWX2aNZhgEjsDrquh1jzJfAdhE50l50CrCWXnyesZqQjhWRVPvfeVOZe+15DhOX82qvKxeRY+3P8MqwfbUu2Z0uSezsOQtrBM8m4NZkx3MI5TgRq5r5MbDSfp2F1bb6FvAZsADoa28vwP12uVcDU8L2dRWw0X7NTXbZOlj+Qg6MShqO9R9+I/A04LeXB+z5jfb64WHvv9X+LDbQgdEaSS7rRGCZfa6fxxp90qvPM/ALYD2wBvgH1siiXnWegSew+lDqsWqG34zneQWm2J/fJuA+ogYwtPTSW2IopZSK4NSmJKWUUq3QxKCUUiqCJgallFIRNDEopZSKoIlBKaVUBE0MyjFE5BGx78TaXXTHmJTS4arKMUQkC+vf/H4RKcK6adn1CTp2IdaFWTnGmD0txZSIOJTqCE/7myjVOxhjyuK9TxHxGWPqOvv+rohJqUOlTUnKMZqabUTkEWAG8F0RMfarwN5mtIi8IiIV9sNTnhCRgS3s40ciUox950oR+bqILA1739MiMtheV4BVWwAosY/3SPj+wvbvF5E/isguEQmKyAcicmLY+kL7/aeI9TCaahFZFv7AFqUOlSYG5UQ3AIuBh7HuV5+HdR+iPGAh1u0DpmHdxC0deEFEwv+vzADGY93p8xR7mQ/4OTABOAfoj3WrA7Buh3yRPT3GPt4NrcT2O+BSrNsbTMK67cHrTTdUC/MbrLurTsa6Udy/OvRkLqU6QJuSlOMYY8pEpA6oNtbN6QAQkW8Dq4wxPwpbdiVQinW/maYbrwWBq4wxtWH7fCjsEJvtfa0TkXxjTLGIlNrrdof3MYSzn6/wbayntL1iL7sO6+6x3wV+Erb5T40x79jb3A4s4uB77yvVKVpjUOqAo4HpIlLZ9OLAw08OD9tuTXhSABCRySLygohsE5EKrJvdAQyN4fiHA17gvaYFxphGrNrN6KhtPw6b/sL+OyCGYynVKq0xKHWAC3gF+EEL63aFTVeFr7B/6b+BdRfMb2DdO78/8C5WE1M8RA8frG9hnf7QU3GhiUE5VR3gjlq2AvgasM1YD4bpqKOwEsGPjTFbAETkwhaORwvHDLfJ3u4EexoRcWM91/jxGOJR6pDoLwzlVFuBaSJSICL97c7l+7Ge+vWkiBwjIsNF5FQRmSciGW3s63OgFrjefs/ZwC+jttmG9cv+bBHJEetRrBGMMVXAX4E7ReQsERllz+cCfznE8irVYZoYlFP9HuvX+VqgBBhqjPkC69d6CHgd+AQrWdTarxYZY0qwnrJ1vr2/nwM3Rm2zw17+K6xmqfta2d2PgCexRkytxB79ZA48GF6pLqdXPiullIqgNQallFIRNDEopZSKoIlBKaVUBE0MSimlImhiUEopFUETg1JKqQiaGJRSSkXQxKCUUirC/wd6GaaxVT6LpwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# learning curve \n",
    "plt.plot(loss_set[:,0], loss_set[:,1], label='loss')\n",
    "plt.plot(loss_set[:,0], loss_set[:,2], label='accuracy')\n",
    "plt.xlabel('iteration', fontsize=14)\n",
    "plt.ylabel('loss', fontsize=14)\n",
    "plt.title('iter vs Loss/Accuracy', fontsize=14)\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
